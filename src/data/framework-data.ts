interface FrameworkControl {
  Domain: string;
  Master: string;
  Topic: string;
  'Control Statement': string;
  ISO42001?: string;
  ISO27001?: string;
  ISO27701?: string;
  'EU AI ACT'?: string | number;
  'NIST RMF'?: string;
  SOC2?: string;
  'Key control activities'?: string;
  'Required Evidence'?: string;
  'Control test plan and procedures'?: string;
}

export const frameworkData = {
  data: [
    {
      Domain: "Governance & Leadership",
      Master: "GL-1",
      Topic: "Executive Commitment and Accountability",
      "Control Statement": "The organisation's executive leadership shall establish, document, and maintain formal accountability for AI governance through approved policies that align with organisational objectives and values. These policies shall be reviewed at planned intervals by executive leadership to ensure continued effectiveness and relevance. Executive leadership shall demonstrate active engagement in AI risk decisions and maintain ultimate accountability for the organisation's AI systems.",
      ISO42001: "4.1 5.1 5.2 9.3 A.2.2 A.2.3 A.2.4",
      ISO27001: "5.1 5.2 9.3 A.5.1 A.5.2",
      ISO27701: "6.1.1 6.1.2",
      "EU AI ACT": 4.1,
      "NIST RMF": "Govern 1.1 Govern 2.3 Govern 3.1",
      SOC2: "CC.1.1 CC.1.2 CC.1.3 CC.1.4 CC.1.5 CC.5.3",
      "Key control activities": "- Establish and document an AI governance policy that aligns with organizational objectives and values\n- Review and update the policy at least annually (or as per defined intervals)\n- Ensure executive leadership actively participates in AI risk decisions (e.g., through regular meetings or reviews)\n- Assign ultimate accountability for AI systems to a specific executive role (e.g., Chief AI Officer or equivalent)",
      "Required Evidence": "- Copies of the approved AI governance policy\n- Records of policy reviews, including dates, reviewers, and changes made\n- Meeting minutes or decision logs showing executive leadership involvement in AI risk decisions\n- Documentation of the assigned accountability (e.g., organizational chart or role description)",
      "Control test plan and procedures": "- Verify the existence and accessibility of the AI governance policy\n- Check records to confirm policy reviews occur at defined intervals (e.g., annually)\n- Review meeting minutes to ensure executive leadership is actively engaged in AI risk decisions\n- Confirm documentation exists that clearly assigns ultimate accountability for AI systems\n- Ensure the policy includes pass/fail criteria (e.g., compliance with ISO 42001 or EU AI Act) and corrective actions for noncompliance"
    },
    {
      Domain: "Governance & Leadership",
      Master: "GL-2",
      Topic: "Roles, Responsibilities & Resources",
      "Control Statement": "The organisation shall define, document, and maintain clear roles and responsibilities for AI governance, ensuring appropriate segregation of duties and allocation of resources. These roles shall be staffed with competent individuals who understand their responsibilities for AI system development, deployment, and oversight. The organisation shall maintain documentation of required resources, including personnel competencies, tools, and infrastructure needed for effective AI governance.",
      ISO42001: "5.3 7.1-7.3 A.3.2 A.4.2",
      ISO27001: "5.3 7.1-7.3 A.6.1 A.6.2 A.7.2",
      ISO27701: "6.2.1 6.2.2 7.2.2 9.2.3",
      "EU AI ACT": "22.1 22.2 26.3",
      "NIST RMF": null,
      SOC2: "CC.1.3 CC.1.4",
      "Key control activities": "- Define and document roles and responsibilities for AI governance, including segregation of duties (e.g., development, deployment, oversight).\n- Ensure roles are staffed with competent individuals (e.g., through skills assessment or training).\n- Document required resources, including personnel competencies, tools, and infrastructure.\n- Review and update roles, responsibilities, and resource documentation annually.",
      "Required Evidence": "- Organizational charts or role descriptions outlining AI governance roles and responsibilities.\n- Job descriptions or competency matrices for AI governance personnel.\n- Records of resource allocation (e.g., budgets, procurement documents for tools and infrastructure).\n- Documentation of annual reviews of roles, responsibilities, and resources.",
      "Control test plan and procedures": "- Verify that roles and responsibilities are clearly documented and aligned with segregation of duties.\n- Check that personnel have the required competencies (e.g., through training records or certifications).\n- Review resource allocation records to ensure tools and infrastructure are adequately provided.\n- Confirm annual reviews are conducted and documented.\n- Ensure the documentation includes specific indicators for pass/fail (e.g., all roles filled by competent personnel) and corrective actions (e.g., retraining or reallocation)."
    },
    {
      Domain: "Governance & Leadership",
      Master: "GL-3",
      Topic: "Strategic Alignment & Objectives",
      "Control Statement": "The organisation shall document clear objectives for the responsible development and use of AI systems, ensuring alignment between business goals, ethical principles, and regulatory requirements. These objectives shall be integrated into organisational practices and regularly reviewed to maintain effectiveness. The organisation shall foster an environment that promotes critical thinking and safety-first approaches to AI development and deployment.",
      ISO42001: "4.1-4.4 5.2 6.2-6.3 A.2.2-A.2.4 A.6.1.2 A.9.3 A.9.4",
      ISO27001: "4.1-4.4 6.2-6.3",
      ISO27701: "A.7.2.1 A.7.2.2 B.8.2.2",
      "EU AI ACT": null,
      "NIST RMF": "Map 1.3 Map 1.4 Govern 1.1 Govern 1.2 Govern 4.1 Govern 3.1",
      SOC2: null,
      "Key control activities": "- Document AI objectives that align with business goals, ethical principles, and regulatory requirements (e.g., ISO 42001, EU AI Act).\n- Integrate these objectives into organizational practices (e.g., through policies, training, or workflows).\n- Review and update objectives at least annually to ensure relevance and effectiveness.\n- Implement initiatives to promote critical thinking and safety-first approaches (e.g., training programs or ethical AI workshops).",
      "Required Evidence": "- Documentation of AI objectives, showing alignment with business goals, ethics, and regulations.\n- Records of how objectives are integrated into practices (e.g., policy documents, training materials).\n- Minutes from annual review meetings of AI objectives.\n- Evidence of initiatives promoting critical thinking and safety (e.g., training session records, workshop agendas).",
      "Control test plan and procedures": "- Verify that AI objectives are documented and aligned with business goals, ethics, and regulations.\n- Check that objectives are integrated into organizational practices (e.g., through policy references or training logs).\n- Review records to confirm annual reviews of objectives.\n- Assess whether initiatives for critical thinking and safety are in place and effective (e.g., through participant feedback or outcome metrics).\n- Ensure documentation includes pass/fail criteria (e.g., objectives met or not) and corrective actions (e.g., revising objectives or retraining staff)."
    },
    {
      Domain: "Risk Management",
      Master: "RM-1",
      Topic: "Risk Management Framework and Governance",
      "Control Statement": "The organisation shall establish, document, and maintain a comprehensive risk management system covering the entire AI lifecycle. This system shall define clear roles, responsibilities, and processes for identifying, assessing, treating, and monitoring AI-related risks. The framework shall incorporate regular reviews by executive leadership and ensure risk management activities align with organisational risk tolerance. Risk management processes shall be transparent, documented, and appropriately resourced to maintain effectiveness.",
      ISO42001: "6.1",
      ISO27001: 6.1,
      ISO27701: "12.2.1 A.7.2.5 A.7.2.8 B.8.2.6",
      "EU AI ACT": "9.1 9.2",
      "NIST RMF": "Govern 1.3 Govern 1.4 Govern 1.5 Map 1.5",
      SOC2: "CC3.1",
      "Key control activities": "- Establish and document a comprehensive risk management system covering the entire AI lifecycle.\n- Define clear roles, responsibilities, and processes for identifying, assessing, treating, and monitoring AI-related risks.\n- Incorporate regular reviews by executive leadership (e.g., quarterly or annually).\n- Ensure risk management activities align with organisational risk tolerance.\n- Make risk management processes transparent, documented, and appropriately resourced (e.g., allocate budget and personnel).",
      "Required Evidence": "- Risk management system documentation (policies, procedures, processes).\n- Risk registers and assessment reports.\n- Minutes of executive leadership reviews (e.g., quarterly or annual).\n- Resource allocation records (e.g., budget approvals, staffing plans).\n- Storage: Centralized GRC system; Sample size: All current and historical risk-related documents.",
      "Control test plan and procedures": "- Verify the existence and accessibility of the documented risk management system.\n- Check that roles and responsibilities are clearly defined (e.g., via organizational charts or role descriptions).\n- Review risk registers and assessment reports to ensure regular updates (e.g., quarterly).\n- Confirm that executive leadership reviews are held as scheduled (e.g., quarterly or annually).\n- Ensure alignment with organisational risk tolerance (e.g., through documented risk appetite statements).\n- Verify that risk management processes are transparent and adequately resourced (e.g., budget and personnel records).\n- Pass/Fail: All risks identified, assessed, treated, and monitored; corrective actions for gaps (e.g., resource reallocation)."
    },
    {
      Domain: "Risk Management",
      Master: "RM-2",
      Topic: "Risk Identification and Impact Assessment",
      "Control Statement": "The organisation shall conduct and document comprehensive impact assessments for AI systems, evaluating potential effects on individuals, groups, and society throughout the system lifecycle. These assessments shall consider fundamental rights, safety implications, environmental impacts, and effects on vulnerable populations. The organisation shall maintain a systematic approach to identifying both existing and emerging risks, including those from third-party components and systems.",
      ISO42001: "6.1.1-6.1.2 6.1.4 8.4 A.5.2 A.5.3 A.5.4 A.5.5",
      ISO27001: "6.1.2",
      ISO27701: "A.7.2.5 A.7.3.10 A.7.4.4",
      "EU AI ACT": "9.9 27.1",
      "NIST RMF": "Map 1.1 Map 3.1 Map 3.2 Measure 2.6 Measure 2.7 Measure 2.8 Measure 2.10 Measure 2.12",
      SOC2: "CC3.2",
      "Key control activities": "- Conduct and document comprehensive impact assessments for AI systems throughout their lifecycle (e.g., pre-deployment, post-deployment, and annually).\n- Assess potential effects on individuals, groups, and society, including fundamental rights, safety, environmental impacts, and vulnerable populations.\n- Maintain a systematic approach to identifying both existing and emerging risks, including from third-party components (e.g., via vendor risk assessments).\n- Review and update impact assessments annually or when significant changes occur.",
      "Required Evidence": "- Impact assessment reports, including methodologies, findings, and mitigation strategies.\n- Documentation of risk identification processes (e.g., risk matrices or heatmaps).\n- Records of third-party risk assessments (e.g., vendor due diligence reports).\n- Storage: GRC system; Sample size: All AI systems' impact assessments for the current year and past three years.",
      "Control test plan and procedures": "- Verify that impact assessments are conducted for all AI systems as required (e.g., pre-deployment and annually).\n- Review assessment reports to ensure they cover all necessary aspects (e.g., individuals, groups, society, fundamental rights, safety, environment, vulnerable populations).\n- Check that systematic risk identification processes are in place (e.g., documented methodologies for risk discovery).\n- Confirm that third-party risks are assessed (e.g., via vendor questionnaires or audits).\n- Ensure assessments are reviewed and updated as required (e.g., annually or upon system changes).\n- Pass/Fail: All required assessments completed; corrective actions for incomplete or inadequate assessments (e.g., reassessment or system adjustments)."
    },
    {
      Domain: "Risk Management",
      Master: "RM-3",
      Topic: "Risk Treatment and Control Implementation",
      "Control Statement": "The organisation shall implement appropriate technical and organisational measures to address identified risks, ensuring controls are proportionate to risk levels and organisational risk tolerance. Risk treatment strategies shall be documented and prioritised based on impact and likelihood, with clear accountability for implementation. The organisation shall maintain specific protocols for high-risk AI systems, including quality management systems and compliance verification processes.",
      ISO42001: "6.1.3",
      ISO27001: "6.1.3",
      ISO27701: "A.7.4.1 A.7.4.2 A.7.4.4 A.7.4.5",
      "EU AI ACT": "8.1 8.2 17.1 9.3 9.4 9.5",
      "NIST RMF": "Manage 1.2 Manage 1.3 Manage 1.4",
      SOC2: "CC5.1 CC9.1",
      "Key control activities": "- Implement technical and organizational measures to address identified risks (e.g., data encryption, access controls, training programs).\n- Ensure controls are proportionate to risk levels and organizational risk tolerance (e.g., high-risk systems require more stringent controls).\n- Document risk treatment strategies and prioritize based on impact and likelihood (e.g., using a risk matrix).\n- Assign clear accountability for implementation (e.g., specific roles like AI Risk Officer).\n- Maintain specific protocols for high-risk AI systems, including quality management systems (e.g., ISO 9001) and compliance verification processes (e.g., third-party audits).",
      "Required Evidence": "- Risk treatment plans and strategies (e.g., documented action plans).\n- Records of implemented controls (e.g., system configurations, training logs).\n- Quality management system documentation for high-risk AI systems (e.g., ISO 9001 certification).\n- Compliance verification reports (e.g., audit reports or self-assessment logs).\n- Storage: GRC system; Sample size: All risk treatment documentation for current and past year.",
      "Control test plan and procedures": "- Verify that risk treatment measures are implemented as per documented plans.\n- Check that controls are proportionate to identified risks (e.g., via risk assessment cross-referencing).\n- Review prioritization of risk treatments based on impact and likelihood (e.g., via risk matrix).\n- Ensure accountability is clearly assigned (e.g., via role descriptions or accountability matrices).\n- Confirm that specific protocols for high-risk AI systems are in place (e.g., quality management processes, compliance checks).\n- Pass/Fail: All identified risks have proportionate treatments; corrective actions for gaps (e.g., additional controls or re-prioritization)."
    },
    {
      Domain: "Risk Management",
      Master: "RM-4",
      Topic: "Risk Monitoring and Response",
      "Control Statement": "The organisation shall implement continuous monitoring processes to track the effectiveness of risk controls and identify emerging risks throughout the AI lifecycle. This shall include mechanisms for detecting and responding to previously unknown risks, regular evaluation of third-party risk exposure, and processes for incident response and recovery. The organisation shall maintain documentation of monitoring activities and ensure appropriate escalation paths for risk-related issues.",
      ISO42001: "6.1.3 8.1-8.3",
      ISO27001: "6.1.3 8.1-8.3",
      ISO27701: "A.7.4.3 A.7.4.9 B.8.2.4 B.8.2.5 B.8.4.3",
      "EU AI ACT": 9.6,
      "NIST RMF": "Measure 3.1 Measure 3.2 Manage 2.1 Manage 2.2 Manage 2.3 Manage 3.1 Govern 6.1 Govern 6.2",
      SOC2: "CC3.4 CC9.2",
      "Key control activities": "- Implement continuous monitoring processes to track the effectiveness of risk controls (e.g., via automated tools or periodic reviews).\n- Identify emerging risks throughout the AI lifecycle (e.g., through threat intelligence or incident reporting).\n- Include mechanisms for detecting and responding to previously unknown risks (e.g., anomaly detection systems).\n- Regularly evaluate third-party risk exposure (e.g., quarterly vendor risk reviews).\n- Maintain processes for incident response and recovery (e.g., documented incident response plans).\n- Document monitoring activities and ensure appropriate escalation paths for risk-related issues (e.g., via escalation matrices).",
      "Required Evidence": "- Monitoring reports and logs (e.g., system logs, audit trails).\n- Incident response and recovery plans (e.g., documented procedures).\n- Records of third-party risk evaluations (e.g., vendor audit reports).\n- Documentation of escalation procedures and actions taken (e.g., issue logs).\n- Storage: GRC system; Sample size: All monitoring and incident records for current year.",
      "Control test plan and procedures": "- Verify that continuous monitoring processes are operational (e.g., via system configurations or tool usage logs).\n- Review monitoring reports to ensure they cover all required areas (e.g., control effectiveness, emerging risks).\n- Check that mechanisms for detecting emerging risks are effective (e.g., via threat intelligence reports).\n- Ensure third-party risks are regularly evaluated (e.g., quarterly reviews).\n- Confirm that incident response and recovery processes are tested and updated (e.g., via drill records).\n- Verify that documentation of monitoring activities is complete and accurate (e.g., via audit trails).\n- Pass/Fail: All monitoring activities are conducted as scheduled; corrective actions for gaps (e.g., process improvements or additional monitoring)."
    },
    {
      Domain: "Regulatory Operations",
      Master: "RO-1",
      Topic: "Regulatory Compliance Framework",
      "Control Statement": "The organisation shall establish, document, and maintain a comprehensive framework for ensuring compliance with applicable AI regulations and standards. This framework shall include processes for identifying relevant requirements, assessing applicability, implementing necessary controls, and verifying ongoing compliance. The organisation shall maintain systematic processes for tracking and implementing new regulatory requirements, conducting conformity assessments, maintaining necessary certifications, and ensuring timely renewal of compliance documentation. Special attention shall be given to high-risk AI system requirements and prohibited practices. The organisation shall implement processes to track changes that may affect compliance status and maintain evidence of continued conformity with legal obligations",
      ISO42001: null,
      ISO27001: "A.18.1",
      ISO27701: "18.2.1 A.7.2.1-A.7.2.4 B.8.2.1-B.8.2.2 B.8.2.4-B.8.2.5",
      "EU AI ACT": "5.1 5.2 6.1-6.4 8.1-8.2 40.1 41.1 42.1 43.1-43.4 44.2-44.3 47.1-47.4 49.1-49.3",
      "NIST RMF": "Govern 1.1 Map 4.1",
      SOC2: "CC1.5",
      "Key control activities": "- Monthly, the Compliance Manager updates the Regulatory Requirements Register using the Compliance Tracking Tool\n- Quarterly, the Legal team reviews new and updated AI regulations using the Regulatory Change Assessment Framework\n- For each high-risk AI system, the Compliance Team conducts conformity assessments using the Conformity Assessment Checklist\n- Annually, the Certification Manager reviews and renews required certifications using the Certification Management System\n- Weekly, the Compliance Analyst monitors regulatory changes using the Regulatory Intelligence Platform",
      "Required Evidence": "- Regulatory Requirements Register with updates (Excel format)\n- Quarterly Regulatory Change Assessment reports (PDF format)\n- Conformity Assessment documentation for high-risk systems (PDF format)\n- Annual Certification Review and Renewal records (PDF format)\n- Weekly Regulatory Change Monitoring logs (System logs)\n- Compliance framework documentation (PDF format)\n- Control implementation evidence (PDF format)\n- Certification maintenance records (PDF format)",
      "Control test plan and procedures": "- Review compliance framework implementation:\n  - Verify framework documentation\n  - Check process adherence\n  - Confirm regular updates\n- Assess regulatory tracking:\n  - Review monitoring process\n  - Verify change assessment\n  - Check implementation plans\n- Evaluate high-risk system compliance:\n  - Examine conformity assessments\n  - Verify control implementation\n  - Check prohibited practices\n- Review certification management:\n  - Verify current certifications\n  - Check renewal tracking\n  - Confirm documentation maintenance"
    },
    {
      Domain: "Regulatory Operations",
      Master: "RO-2",
      Topic: "Transparency, Disclosure and Reporting",
      "Control Statement": "The organisation shall implement mechanisms to ensure appropriate transparency regarding AI systems, including clear notification of AI use, disclosure of automated decision-making, and communication of significant system changes. The organisation shall establish and maintain processes for reporting incidents, safety issues, and non-compliance to relevant authorities and affected stakeholders. This shall include clear procedures for incident detection, assessment, notification timelines, and follow-up actions.",
      ISO42001: "A.8.3 A.8.5",
      ISO27001: "A.6.3",
      ISO27701: "6.2.3 A.7.3.2-A.7.3.3 A.7.3.8-A.7.3.9 A.7.5.3-A.7.5.4 B.8.5.3-B.8.5.6",
      "EU AI ACT": "50.1-50.5 86.1-86.3 20.1 20.2 60.7 60.8",
      "NIST RMF": "Govern 6.1 Map 4.1",
      SOC2: "CC2.3 P1.1 P1.2 P1.3",
      "Key control activities": "- Monthly, the AI Product Manager reviews all AI system interfaces to verify appropriate AI disclosure notices using the Transparency Checklist\n- For each system update, the Development Lead completes the Change Impact Assessment form that includes transparency requirements verification\n- Quarterly, the UX Designer audits all user touchpoints for clarity of AI notifications using the UX Audit Tool\n- Before any significant system change, the Product Manager ensures updated disclosure documentation is prepared and approved by Legal\n- The Communications Manager maintains a stakeholder notification template for system changes that is reviewed annually by Legal and updated as needed",
      "Required Evidence": "- Completed monthly AI Transparency Checklists for each system (PDF format)\n- Change Impact Assessment forms showing transparency requirements verification (PDF format)\n- Quarterly UX Audit reports with screenshots of AI disclosures (PDF format with attachments)\n- User interface mockups and implemented screens showing AI notifications (Image files)\n- Legal approval emails for disclosure language (Email archive)\n- Stakeholder notification templates with revision history (Word documents)\n- Sample communications sent to users regarding significant system changes (Email archives)\n- Record of automated decision-making notifications with timestamps (System logs)",
      "Control test plan and procedures": "- Select three AI systems and examine the last three monthly Transparency Checklists\n - For each selected system, access the live environment and verify AI disclosures are present, visible, and accurate\n - Review the last five Change Impact Assessments to confirm transparency requirements were evaluated\n - Select two significant system changes from the past six months and verify that: ◦ Disclosure documentation was updated prior to deployment ◦ Legal approval was obtained and documented ◦ Users were notified appropriately about the changes\n - Control passes if all transparency disclosures are present, accurate, and properly communicated; fails if disclosures are missing, inaccurate, or not properly communicated"
    },
    {
      Domain: "Regulatory Operations",
      Master: "RO-3",
      Topic: "Record-Keeping",
      "Control Statement": "The organisation shall maintain comprehensive documentation and records demonstrating compliance with AI regulatory requirements. This shall include technical documentation, conformity assessments, impact analyses, test results, and evidence of ongoing monitoring. The organisation shall establish retention periods aligned with regulatory requirements, implement secure storage systems, and ensure documentation remains accessible to authorised parties throughout required retention periods.",
      ISO42001: null,
      ISO27001: "A.7.2",
      ISO27701: "8.2.3 A.7.2.8 A.7.3.1 A.7.4.3 A.7.4.6-A.7.4.8 B.8.2.6 B.8.4.1-B.8.4.2",
      "EU AI ACT": "11.1 11.3 18.1 19.1 19.2 71.2 71.3",
      "NIST RMF": "Map 4.1 Measure 2.12",
      SOC2: "P3.1 P3.2 P3.3",
      "Key control activities": "- Monthly, the Documentation Manager reviews the AI System Documentation Repository to ensure all required documentation is current and compliant\n- For each system update, the AI Engineer updates technical documentation and submits for review to the Technical Lead within 5 business days\n- Quarterly, the Compliance Officer conducts a documentation audit using the Documentation Completeness Checklist\n- Annually, the Records Manager reviews documentation retention policies against regulatory requirements and updates as needed\n- During system development, the AI Project Manager ensures documentation is created according to the Documentation Standards Guide",
      "Required Evidence": "- AI System Documentation Repository inventory report showing all documents with last update dates (Excel format)\n- Technical documentation change logs with approvals (PDF format)\n- Quarterly Documentation Audit reports with findings and remediation actions (PDF format)\n- Annual Documentation Retention Policy review documentation (Word document)\n- Sample of critical AI system documentation (conformity assessments, impact analyses, test results) (Various formats)\n- Access logs for documentation repository showing appropriate permission controls (System logs)\n- Documentation Standards Guide with revision history (Word document)\n- Training records showing staff completion of documentation procedures training (LMS report)",
      "Control test plan and procedures": "- Select two AI systems and verify that all required documentation types are present in the repository\n - For each selected system, check that documentation was updated following the last three system changes\n - Review the last two quarterly documentation audits and verify that: ◦ All findings were documented ◦ Remediation actions were assigned ◦ Follow-up verification was completed\n - Select one high-risk AI system and verify retention of all required documentation per regulatory requirements\n - Verify access controls by confirming that only authorized personnel can access, modify, or delete documentation\n - Control passes if documentation is complete, current, and properly secured; fails if documentation is missing, outdated, or improperly managed"
    },
    {
      Domain: "Regulatory Operations",
      Master: "RO-4",
      Topic: "Post-Market Monitoring",
      "Control Statement": "The organisation shall implement comprehensive post-market monitoring systems for deployed AI systems, including mechanisms for tracking performance, identifying issues, and implementing corrective actions. This shall include processes for reporting incidents to relevant authorities, maintaining required documentation, and conducting periodic reviews of system performance. The organisation shall ensure appropriate escalation paths exist for identified issues and maintain clear procedures for implementing necessary corrective actions.",
      ISO42001: "A.8.3",
      ISO27001: null,
      ISO27701: "6.2.3 A.7.3.6-A.7.3.7 A.7.3.10 A.7.4.3 B.8.3.1 B.8.5.7-B.8.5.8",
      "EU AI ACT": "72.1-72.4 79.4 80.4-80.5",
      "NIST RMF": "Govern 6.1 Measure 2.12",
      SOC2: "CC1.5",
      "Key control activities": "- Daily, the Operations team reviews automated system monitoring alerts and documents issues in the Incident Management System\n- Weekly, the AI Performance Analyst reviews performance metrics against established thresholds using the Performance Dashboard\n- Monthly, the AI Product Manager reviews user feedback related to AI system performance using the Feedback Analysis Report\n- Quarterly, the AI Governance Committee reviews system performance trends and incident reports using the Quarterly Performance Review template\n- For high-risk AI systems, the Risk Manager conducts monthly detailed performance reviews against predefined risk thresholds",
      "Required Evidence": "- Daily system monitoring logs with alert records and resolution documentation (System logs)\n- Weekly Performance Analysis Reports with metrics, trends, and anomalies identified (PDF format)\n- Monthly Feedback Analysis Reports with categorized user feedback and actions taken (Excel format)\n- Quarterly Performance Review reports with committee sign-off (PDF format)\n- Incident reports with investigation findings, corrective actions, and regulatory notifications when applicable (PDF format)\n- Post-incident review documentation showing root cause analysis and preventive measures (Word documents)\n- Regulatory authority notification records where required (Email archives)\n- Corrective Action implementation records with verification (PDF format)",
      "Control test plan and procedures": "- Review the last 30 days of system monitoring logs and verify that alerts were addressed per established procedures\n - Select three performance incidents from the past quarter and trace through the response process to confirm: ◦ Initial detection and logging occurred per procedures ◦ Appropriate escalation took place within required timeframes ◦ Investigation was thorough and well-documented ◦ Corrective actions were implemented and verified ◦ Required notifications were made to authorities (if applicable)\n - Review the last two Quarterly Performance Review reports and verify they were reviewed by the AI Governance Committee\n - For one high-risk AI system, review the last three monthly performance reviews against risk thresholds\n - Control passes if monitoring activities are consistently performed and documented, with appropriate response to identified issues; fails if monitoring is inconsistent or responses inadequate\n - If failure, the AI Operations Manager must immediately review monitoring processes and implement improvements within 15 business days"
    },
    {
      Domain: "System, Data and Model Lifecycle",
      Master: "LC-1",
      Topic: "Data Quality and Governance",
      "Control Statement": "The organisation shall establish and maintain comprehensive data governance processes ensuring high-quality data throughout the AI system lifecycle. This shall include documented requirements and procedures for data collection, processing, and validation, ensuring datasets are relevant, representative, and statistically suitable for their intended purpose. The organisation shall implement processes for bias detection and mitigation, maintain clear data provenance records, and ensure data reflects the specific geographical, behavioural, and functional settings where AI systems will be used.",
      ISO42001: "A.7.2-A.7.6",
      ISO27001: null,
      ISO27701: "A.7.4.1-A.7.4.2 A.7.4.6-A.7.4.8 B.8.4.1-B.8.4.2",
      "EU AI ACT": "10.1-10.6",
      "NIST RMF": "Map 2.1",
      SOC2: null,
      "Key control activities": "- Before data collection, the Data Governance team reviews data requirements using the Data Quality Framework\n- Monthly, the Data Quality Manager conducts data quality assessments using the Quality Monitoring Dashboard\n- For each dataset, the Data Scientist verifies statistical properties using the Dataset Validation Tool\n- Quarterly, the Data Steward reviews data governance policies using the Policy Review Checklist\n- Annually, the Data Governance Committee evaluates data quality metrics using the Quality Metrics Dashboard",
      "Required Evidence": "- Data Quality Framework documentation with requirements (PDF format)\n- Monthly Data Quality Assessment reports (PDF format)\n- Dataset Validation reports with statistical analysis (PDF format)\n- Quarterly Policy Review documentation (PDF format)\n- Annual Data Quality Metrics evaluation (PDF format)\n- Data governance policy documentation (PDF format)\n- Data quality monitoring logs (System logs)\n- Data provenance documentation (PDF format)",
      "Control test plan and procedures": "- Review data quality processes:\n  - Verify framework implementation\n  - Check monitoring procedures\n  - Confirm quality metrics tracking\n- Assess dataset validation:\n  - Review statistical properties\n  - Check bias detection results\n  - Verify data completeness\n- Evaluate data governance:\n  - Check policy compliance\n  - Review stewardship roles\n  - Verify documentation maintenance\n- Examine quality metrics:\n  - Analyze trend reports\n  - Check improvement actions\n  - Verify stakeholder reporting\n- Control passes if data quality processes are consistently followed; fails if processes are bypassed or documentation is incomplete"
    },
    {
      Domain: "System, Data and Model Lifecycle",
      Master: "LC-2",
      Topic: "System Development and Lifecycle Management",
      "Control Statement": "The organisation shall define, document, and maintain processes for responsible AI system development across the entire lifecycle, from requirements specification through deployment and eventual decommissioning. The organisation shall maintain clear records of system objectives, technical implementation decisions, and operational constraints throughout development and deployment phases.",
      ISO42001: "A.6.1.2-A.6.1.3 A.6.2.2-A.6.2.3 A.6.2.5",
      ISO27001: null,
      ISO27701: "A.7.4.1-A.7.4.2 A.7.4.5-A.7.4.8 B.8.4.1-B.8.4.2",
      "EU AI ACT": null,
      "NIST RMF": "Map 1.6 Govern 1.7",
      SOC2: "CC8.1 CC8.2",
      "Key control activities": "- Before project initiation, the AI Project Manager completes the System Requirements Specification using the approved template\n- During design phase, the AI Architect creates and updates the System Architecture Document that is reviewed by the Security and Privacy teams\n- At each development milestone, the AI Engineering Lead conducts a Technical Implementation Review using the Review Checklist\n- Before deployment, the Quality Assurance Manager performs a final validation using the Pre-Deployment Validation Checklist\n- Quarterly, the AI Governance Committee reviews a sample of systems to verify lifecycle documentation is complete",
      "Required Evidence": "- System Requirements Specification documents (PDF format)\n- System Architecture Documentation with review history (PDF format)\n- Technical Implementation Review reports (PDF format)\n- Pre-Deployment Validation records (PDF format)\n- Quarterly System Documentation Review reports (PDF format)\n- Development lifecycle documentation (PDF format)\n- Technical decision records (PDF format)\n- Operational constraints documentation (PDF format)",
      "Control test plan and procedures": "- Review system development documentation:\n  - Verify requirements specification\n  - Check architecture documentation\n  - Confirm technical decisions\n- Assess development milestones:\n  - Review implementation reviews\n  - Check validation records\n  - Verify timeline compliance\n- Evaluate deployment process:\n  - Examine pre-deployment checks\n  - Verify security reviews\n  - Confirm stakeholder sign-offs\n- Review lifecycle management:\n  - Check documentation completeness\n  - Verify constraint documentation\n  - Assess decommissioning plans\n- Control passes if lifecycle processes are consistently followed; fails if documentation is incomplete or processes are bypassed"
    },
    {
      Domain: "System, Data and Model Lifecycle",
      Master: "LC-3",
      Topic: "Resource Management and Infrastructure",
      "Control Statement": "The organisation shall document and maintain inventories of all resources required for AI system development and operation, including data resources, tooling, computing infrastructure, and human competencies. This shall include clear allocation of responsibilities, documentation of system dependencies, and maintenance of resource specifications throughout the system lifecycle.",
      ISO42001: "A.4.3 A.4.5 A.4.6 A.10.2",
      ISO27001: "A.8.1 A.8.2",
      ISO27701: "A.7.2.6 A.7.2.7 B.8.5.6",
      "EU AI ACT": null,
      "NIST RMF": "Govern 1.6",
      SOC2: null,
      "Key control activities": "- Quarterly, the Resource Manager updates the AI Resource Inventory using the Resource Management Tool\n- Monthly, the AI Engineering Lead reviews resource allocation and utilization using the Resource Utilization Report\n- Before new AI projects, the Project Manager completes the Resource Requirements Assessment using the approved template\n- Annually, the Training Manager assesses staff competencies against required skills using the Competency Assessment Framework\n- When resource dependencies change, the System Owner updates the System Dependency Documentation within 5 business days",
      "Required Evidence": "- AI Resource Inventory showing data resources, tools, infrastructure, and human competencies (Excel format)\n- Monthly Resource Utilization Reports with analysis of usage patterns (PDF format)\n- Resource Requirements Assessments for all new AI projects (PDF format)\n- Annual Competency Assessment reports with gap analysis (PDF format)\n- System Dependency Documentation with revision history (Word documents)\n- Resource allocation meeting minutes showing decision-making (PDF format)\n- Infrastructure capacity planning documents (PDF format)\n- Tool license and capacity management records (Excel format)",
      "Control test plan and procedures": "- Review the AI Resource Inventory to verify it includes all required resource categories\n  - Select two AI systems and verify that resource dependencies are accurately documented\n  - Review the last three monthly Resource Utilization Reports to confirm regular monitoring occurs\n  - For one new AI project, verify the Resource Requirements Assessment was completed before project initiation\n  - Select five employees involved in AI development and verify current Competency Assessments exist\n  - Control passes if resource management documentation is complete and up-to-date; fails if documentation is incomplete or outdated"
    },
    {
      Domain: "System, Data and Model Lifecycle",
      Master: "LC-4",
      Topic: "Technical Documentation",
      "Control Statement": "The organisation shall maintain comprehensive technical documentation demonstrating compliance throughout the AI system lifecycle. This shall include system characteristics, design specifications, validation results, and operational logs. The organisation shall implement automated logging mechanisms to capture system events, maintain documentation for required retention periods, and ensure documentation remains accessible to relevant stakeholders.",
      ISO42001: "7.5.1-7.5.3 A.6.2.7 A.6.2.8",
      ISO27001: "7.5.1-7.5.3",
      ISO27701: "A.7.2.8 A.7.5.3 A.7.5.4 B.8.2.6 B.8.5.3",
      "EU AI ACT": "11.1-11.3 12.1-12.3 18.1",
      "NIST RMF": "Map 2.2 Map 3.3",
      SOC2: null,
      "Key control activities": "- For each system release, the Technical Writer updates the Technical Documentation Package using the Documentation Checklist\n- Monthly, the AI Engineer reviews system logs to ensure automated logging is functioning properly\n- Quarterly, the Documentation Manager conducts a documentation audit using the Documentation Compliance Checklist\n- Before major version releases, the Quality Assurance team validates technical documentation accuracy using the Documentation Validation Process\n- When system characteristics change, the System Owner updates the System Specification Document within 10 business days",
      "Required Evidence": "- Complete Technical Documentation Packages for each system version (PDF format)\n- Documentation Checklist with sign-off from required stakeholders (PDF format)\n- Monthly system logging verification reports (PDF format)\n- Quarterly Documentation Audit reports with findings and remediation (PDF format)\n- Documentation Validation testing results (PDF format)\n- System Specification Documents with revision history (Word documents)\n- System logs showing operational data collection (System logs)\n- Documentation retention schedule with compliance verification (Excel format)",
      "Control test plan and procedures": "- Select two AI systems and verify complete Technical Documentation Packages exist for the current version\n - For each selected system, verify documentation includes:\n   - System characteristics\n   - Design specifications\n   - Validation results\n   - Operational logs\n - Review system logs from the past 30 days to confirm automated logging is functioning properly\n - For one system that underwent changes in the past quarter, verify the System Specification Document was updated appropriately\n - Control passes if technical documentation is complete, accurate, and up-to-date; fails if documentation is incomplete, inaccurate, or outdated."
    },
    {
      Domain: "System, Data and Model Lifecycle",
      Master: "LC-5",
      Topic: "Change Management & Version Control",
      "Control Statement": "The organisation shall establish and maintain comprehensive processes for managing changes to AI systems throughout their lifecycle. This shall include documented procedures for proposing, evaluating, testing, and implementing changes to models, data, or system components. The organisation shall maintain detailed version control of all system elements, including models, datasets, and software components, with clear records of modifications and their rationale. Changes shall be tested and validated before deployment, with documentation updated to reflect current system state.",
      ISO42001: "A.6.2.5",
      ISO27001: "A.12.2",
      ISO27701: "A.7.3.7 B.8.5.7 B.8.5.8",
      "EU AI ACT": 11.3,
      "NIST RMF": "Map 2.1",
      SOC2: "CC8.1 CC8.2",
      "Key control activities": "- For each system change, the Change Manager completes the Change Request Form and obtains approval from the Change Advisory Board\n- Before implementing changes, the Test Manager verifies test plans using the Change Testing Checklist\n- After each change implementation, the Quality Assurance team validates the change using the Post-Implementation Verification Process\n- Monthly, the Version Control Administrator audits version control systems using the Version Control Audit Checklist\n- Quarterly, the Change Manager reviews change management metrics using the Change Management Dashboard",
      "Required Evidence": "- Change Request Forms with appropriate approvals for all system changes (PDF format)\n- Change Advisory Board meeting minutes documenting change approvals (PDF format)\n- Pre-implementation test plans and results (PDF format)\n- Post-Implementation Verification reports (PDF format)\n- Version control system logs showing all component versions (System logs)\n- Version Control Audit reports (PDF format)\n- Change Management Dashboard reports showing metrics and trends (PDF format)\n- Documentation updates reflecting implemented changes (Various formats)",
      "Control test plan and procedures": "- Select five system changes from the past quarter and verify for each:\n   - Properly completed Change Request Form exists\n   - Change Advisory Board approval was obtained\n   - Testing was conducted and documented\n   - Post-implementation verification was performed\n   - Review the version control system to confirm proper versioning of models, datasets, and code\n   - Examine documentation to verify it was updated to reflect the implemented changes\n   - Review the last two monthly Version Control Audits to confirm they were conducted properly\n   - Control passes if change management procedures are consistently followed with proper documentation; fails if procedures are inconsistently followed or inadequately documented"
    },
    {
      Domain: "Security",
      Master: "SE-1",
      Topic: "Security Governance, Architecture and Engineering",
      "Control Statement": "The organisation shall establish and maintain a comprehensive security governance framework that encompasses security risk management, security policies, standards, and architectures that guide the implementation of security controls across the organisation. The organisation shall ensure continuous monitoring of control effectiveness, manages security incidents, and maintains business continuity capabilities while overseeing third-party security requirements.",
      ISO42001: null,
      ISO27001: "A.5.1-A.5.2 A.6.1-A.6.2 A.6.5 A.7.1-A.7.4 A.12.1-A.12.3 A.17.1-A.17.2 A.18.1-A.18.2",
      ISO27701: "14.2.1 14.2.2",
      "EU AI ACT": null,
      "NIST RMF": null,
      SOC2: "CC2.3 CC3.1 CC3.2 CC5.2 CC7.2 CC7.3 CC9.3",
      "Key control activities": "- Quarterly, the CISO conducts a Security Risk Assessment using the Security Risk Management Framework\n- Annually, the Security Policy Manager reviews and updates security policies using the Policy Review Checklist\n- Monthly, the Security Operations team reviews security control effectiveness using the Security Control Dashboard\n- Quarterly, the Security Incident Response team tests incident response procedures through tabletop exercises\n- Annually, the Business Continuity Manager tests and updates the Business Continuity Plan",
      "Required Evidence": "- Security policies and standards with revision history (PDF)\n- Security Architecture Assessment reports (PDF)\n- Continuous monitoring logs and alerts (System logs)\n- Annual Security Risk Assessment reports (PDF)\n- Incident Response Plan test results (PDF)\n- Security metrics and KPI reports (Dashboard)\n- Third party security assessment reports (PDF)\n- Business continuity test results (PDF)",
      "Control test plan and procedures": "- Review security governance structure\n- Verify committee activities\n- Check decision documentation\n- Review resource allocation\n- Assess oversight effectiveness\n- Verify reporting processes\n- Control passes if oversight is effective; fails if governance gaps exist."
    },
    {
      Domain: "Security",
      Master: "SE-2",
      Topic: "Identity & Access Management",
      "Control Statement": "The organisation shall implement and maintains comprehensive identity and access management controls governing authentication, authorisation, and access monitoring across all systems and applications. This includes the complete lifecycle of identity management from screening to provisioning through deprovisioning, ensuring appropriate access levels are maintained and regularly reviewed. The organisation shall implement strong authentication mechanisms and maintains detailed access logs for all critical systems.",
      ISO42001: null,
      ISO27001: "A.9.1 A.9.2 A.9.3 A.9.4",
      ISO27701: "9.2.1 9.2.2 9.2.4",
      "EU AI ACT": null,
      "NIST RMF": null,
      SOC2: "CC6.1 CC6.2 CC6.3",
      "Key control activities": "- Monthly, the IAM Manager reviews access rights using the Access Review Dashboard\n- Quarterly, the Security Team conducts privileged access audits using the Privileged Account Management Tool\n- For each new system, the Security Architect verifies IAM controls using the IAM Implementation Checklist\n- Weekly, the Security Operations team reviews authentication logs using the SIEM platform\n- Annually, the IAM team tests the access provisioning and deprovisioning process",
      "Required Evidence": "- Monthly Access Review reports with findings (PDF format)\n- Quarterly Privileged Access Audit results (PDF format)\n- IAM Implementation Verification records (PDF format)\n- Weekly Authentication Log Analysis reports (PDF format)\n- Annual Access Process Test results (PDF format)\n- Access policy documentation with review history (PDF format)\n- User access request and approval records (System logs)\n- Access reconciliation reports (Excel format)",
      "Control test plan and procedures": "- Review access management processes:\n  - Verify policy documentation\n  - Check process adherence\n  - Confirm regular updates\n- Assess privileged access controls:\n  - Review approval workflows\n  - Verify access reviews\n  - Check deprovisioning timeliness\n- Test authentication mechanisms:\n  - Verify MFA implementation\n  - Check password policies\n  - Test session management\n- Evaluate monitoring capabilities:\n  - Review alert configurations\n  - Check response procedures\n  - Verify logging completeness\n- Control passes if IAM controls are consistently implemented; fails if controls are bypassed or documentation is incomplete\n- For failures, IAM Manager must implement corrective actions within 5 business days"
    },
    {
      Domain: "Security",
      Master: "SE-3",
      Topic: "Software Security",
      "Control Statement": "The organisation shall ensure all software development and deployment activities follow secure development practices throughout the system development lifecycle. This includes implementing secure coding standards, conducting security testing, managing secure configurations, and maintaining robust change management procedures for all production systems. The organisation shall regularly assess applications for security vulnerabilities and maintain secure development environments.",
      ISO42001: null,
      ISO27001: "A.14.1 A.14.2 A.12.2",
      ISO27701: "14.2.1 14.2.2",
      "EU AI ACT": null,
      "NIST RMF": null,
      SOC2: "CC5.2 CC7.1",
      "Key control activities": "- Before code commits, developers run the Secure Code Analysis Tool and resolve all critical findings\n- Weekly, the Security Engineer conducts security testing using the Security Testing Framework\n- For each release, the Quality Assurance team verifies secure configurations using the Configuration Verification Checklist\n- Monthly, the Application Security Manager reviews vulnerability assessment results using the Vulnerability Management Dashboard\n- Quarterly, the Development Manager audits adherence to secure development standards using the SDLC Audit Tool",
      "Required Evidence": "- Secure Code Analysis Tool reports with resolution documentation (PDF format)\n- Weekly Security Testing results with findings and remediation (PDF format)\n- Configuration Verification Checklists for each release (PDF format)\n- Monthly Vulnerability Assessment reports (PDF format)\n- Quarterly SDLC Audit reports (PDF format)\n- Secure coding standards documentation with review history (PDF format)\n- Security testing procedures and results (PDF format)\n- Change management records showing security approval for production changes (PDF format)",
      "Control test plan and procedures": "- Review secure development practices:\n  - Verify coding standards implementation\n  - Check automated analysis tools\n  - Confirm code review processes\n- Assess security testing procedures:\n  - Review testing methodology\n  - Verify coverage metrics\n  - Check remediation tracking\n- Evaluate configuration management:\n  - Verify baseline documentation\n  - Check change controls\n  - Review deployment procedures\n- Monitor vulnerability management:\n  - Review scanning frequency\n  - Check remediation timelines\n  - Verify reporting processes\n- Control passes if secure development practices are consistently followed; fails if practices are inconsistent or security controls are bypassed."
    },
    {
      Domain: "Security",
      Master: "SE-4",
      Topic: "Data Security",
      "Control Statement": "The organisation shall protect data throughout its lifecycle using appropriate technical and procedural controls, including classification, encryption, and secure handling procedures. This encompasses structured and unstructured data across all storage locations and transmission paths. The organisation shall maintain comprehensive data protection mechanisms, including backup systems, encryption standards, and secure disposal procedures, while ensuring appropriate data classification and handling requirements are enforced.",
      ISO42001: null,
      ISO27001: "A.8.1-A.8.7 A.10.1 A.10.2 A.12.4 A.12.5 A.14.3",
      ISO27701: "8.2.4 8.3.1 8.3.2 8.3.3 10.2.1 10.2.2 11.2.2",
      "EU AI ACT": null,
      "NIST RMF": null,
      SOC2: "CC6.4-CC6.7 C1.1 C1.2 P5.1-P5.4 P5.6",
      "Key control activities": "- Monthly, the Data Protection Officer reviews data classification and handling practices using the Data Protection Audit Checklist\n- Weekly, the Backup Administrator verifies backup integrity using the Backup Verification Process\n- Quarterly, the Security Engineer tests encryption implementation using the Encryption Testing Framework\n- For each new data type, the Data Steward completes the Data Classification Form and implements appropriate controls\n- Annually, the Records Manager reviews and tests data disposal procedures",
      "Required Evidence": "- Monthly Data Protection Audit reports (PDF format)\n- Weekly Backup Verification logs (System logs)\n- Quarterly Encryption Testing results (PDF format)\n- Data Classification Forms for all data types (PDF format)\n- Annual Data Disposal Procedure Testing documentation (PDF format)\n- Data handling training completion records (LMS reports)\n- Encryption standards documentation with implementation evidence (PDF format)\n- Data classification inventory (Excel format)",
      "Control test plan and procedures": "- Review data classification implementation\n- Verify backup processes and recovery capabilities\n- Test encryption effectiveness\n- Check data handling procedures\n- Verify disposal mechanisms\n- Review access controls\n- Control passes if data protection controls are effective; fails if any critical controls are missing or ineffective."
    },
    {
      Domain: "Security",
      Master: "SE-5",
      Topic: "Network Security",
      "Control Statement": "The organisation shall implement and maintain comprehensive network security controls to protect against unauthorised access, ensure secure communications, and maintain the confidentiality and integrity of data in transit. This includes implementing secure network architectures, maintaining network monitoring capabilities, and ensuring appropriate network segmentation. The organisation shall regularly assess network security controls and maintain comprehensive network logging and monitoring capabilities.",
      ISO42001: null,
      ISO27001: "A.13.1-A.13.3 A.12.4 A.12.6 A.10.1 A.10.2",
      ISO27701: "13.2.1",
      "EU AI ACT": null,
      "NIST RMF": null,
      SOC2: "CC6.6 CC7.1 CC7.2",
      "Key control activities": "- Daily, the Network Security Analyst reviews security alerts using the Network Monitoring Dashboard\n- Weekly, the Network Administrator verifies network configurations using the Configuration Management Tool\n- Monthly, the Security Engineer conducts network vulnerability scanning using the approved Vulnerability Scanner\n- Quarterly, the Network Security Manager reviews network segmentation using the Network Architecture Review Process\n- Annually, the Security Assessment team conducts penetration testing of network security controls",
      "Required Evidence": "- Daily Network Security Alert Review logs (System logs)\n- Weekly Network Configuration Verification reports (PDF format)\n- Monthly Network Vulnerability Scan results with remediation plans (PDF format)\n- Quarterly Network Architecture Review reports (PDF format)\n- Annual Penetration Testing reports with findings and remediation (PDF format)\n- Network security architecture documentation with review history (PDF format)\n- Network monitoring logs showing continuous monitoring (System logs)\n- Network segmentation implementation documentation (PDF format)",
      "Control test plan and procedures": "- Review network security alert logs from the past 7 days to verify daily review occurred\n- Examine the last four weekly Network Configuration Verification reports\n- For the last two monthly Network Vulnerability Scans, verify findings were remediated according to SLAs\n- Review the most recent Network Architecture Review to confirm proper segmentation\n- Examine the annual Penetration Testing report to verify findings were addressed\n- Control passes if network security controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented."
    },
    {
      Domain: "Safe Responsible AI",
      Master: "RS-1",
      Topic: "Human Oversight and Intervention",
      "Control Statement": "The organisation shall implement mechanisms for meaningful human oversight of AI systems, ensuring humans maintain appropriate control over AI decision-making. This includes clearly defined procedures for human monitoring, intervention capabilities, and authority to override AI systems when necessary. Personnel responsible for oversight must receive appropriate training and have sufficient competence and authority to fulfill their responsibilities effectively.",
      ISO42001: "A.9.2 A.9.3 A.9.4",
      ISO27001: "A.18.1.1 A.18.2.2 A.6.1 A.6.2",
      ISO27701: "7.2.2 7.2.5",
      "EU AI ACT": "14.1-14.5 26.2 4.1",
      "NIST RMF": "Govern 3.2 Map 3.4 Map 3.5",
      SOC2: "CC1.1 CC2.1",
      "Key control activities": "- Monthly, the AI Oversight Committee reviews system performance reports and intervention logs\n- Quarterly training sessions conducted for oversight personnel on system capabilities and limitations\n- Weekly review of high-risk AI system decisions by domain experts\n- Implementation of human-in-the-loop controls for critical decision points\n- Regular testing of override mechanisms and escalation procedures\n- Documentation of all human interventions and their outcomes",
      "Required Evidence": "- AI System Oversight Manual with defined roles and procedures (PDF)\n- Training records and competency assessments for oversight personnel (Excel)\n- System performance reports with human review annotations (PDF)\n- Intervention logs documenting override decisions and rationale (Excel)\n- Minutes from AI Oversight Committee meetings (PDF)\n- Technical documentation of human-in-the-loop implementation (PDF)\n- Escalation procedure test results and updates (PDF)",
      "Control test plan and procedures": "- Review the last 6 months of oversight committee meeting minutes\n- Verify training completion for all oversight personnel\n- Sample 10 high-risk decisions to confirm human review was performed\n- Test override mechanisms on non-production systems to verify functionality\n- Review intervention logs for proper documentation and follow-up\n- Interview 3 oversight personnel to assess understanding of procedures\n- Control passes if all samples show compliance with procedures; fails if any critical steps were missed."
    },
    {
      Domain: "Safe Responsible AI",
      Master: "RS-2",
      Topic: "Safety",
      "Control Statement": "The organisation shall establish and maintain processes to prevent AI systems from producing outputs that could cause harm to individuals, groups, or society. This includes comprehensive impact assessments, monitoring for potential harms, and implementation of safeguards to prevent prohibited uses or manipulative practices. The organisation must maintain documented evidence of harm prevention measures and regularly assess their effectiveness.",
      ISO42001: "A.5.2 A.5.3 A.5.4 A.5.5",
      ISO27001: "A.12.1",
      ISO27701: "7.2.3 7.2.4",
      "EU AI ACT": "5.1 5.2 9.1-9.3",
      "NIST RMF": "Map 1.1 Map 3.1 Map 3.2 Measure 3.1 Measure 3.2",
      SOC2: "CC4.1 CC5.1",
      "Key control activities": "- Quarterly safety impact assessments for all AI systems.\n- Monthly review of safety monitoring metrics and incident reports.\n- Implementation of safety boundaries and kill switches for high-risk systems.\n- Regular testing of safety mechanisms and fail-safes.\n- Documentation of safety requirements in system design.\n- Continuous monitoring for emerging safety risks.\n- Regular updates to safety controls based on operational feedback.",
      "Required Evidence": "- Safety Impact Assessment Reports (PDF).\n- Safety monitoring dashboards and metrics (Excel).\n- Incident reports and resolution documentation (PDF).\n- Safety mechanism test results (PDF).\n- System design documents with safety controls (PDF).\n- Risk register with safety-related entries (Excel).\n- Safety control update logs (Excel).\n- Training records for safety procedures (PDF).",
      "Control test plan and procedures": "- Review last 4 quarterly safety impact assessments.\n- Verify implementation of identified safety controls.\n- Test emergency stop procedures on 3 critical systems.\n- Review incident reports for proper handling and resolution.\n- Verify safety monitoring systems are active and logging.\n- Sample 5 high-risk operations for safety compliance.\n- Control passes if all safety mechanisms function as designed; fails if any critical safety control is compromised."
    },
    {
      Domain: "Safe Responsible AI",
      Master: "RS-3",
      Topic: "Robustness",
      "Control Statement": "The organisation shall ensure AI systems demonstrate consistent and reliable performance across their intended operating conditions, including edge cases and unexpected scenarios. Systems must be resilient against errors, adversarial attacks, and data quality issues. Regular testing and monitoring shall be conducted to verify robustness, with particular attention to system behavior under stress conditions or when encountering novel situations.",
      ISO42001: "A.9.4",
      ISO27001: "A.17.1 A.17.2",
      ISO27701: "7.2.8",
      "EU AI ACT": "8.1 8.2 15.1 15.4 15.5",
      "NIST RMF": "Map 2.1 Map 2.2 Measure 4.2 Measure 4.3",
      SOC2: "CC7.1 CC8.1",
      "Key control activities": "- Monthly robustness testing including edge cases and stress conditions.\n- Regular adversarial testing of AI systems.\n- Implementation of data quality checks and validation.\n- Continuous monitoring of system performance metrics.\n- Regular updates to robustness measures based on operational data.\n- Documentation of system limitations and boundary conditions.\n- Implementation of fallback mechanisms for system failures.",
      "Required Evidence": "- Robustness Test Reports and Results (PDF).\n- System Performance Monitoring Logs (Excel).\n- Adversarial Test Documentation (PDF).\n- Data Quality Reports (Excel).\n- System Boundary Documentation (PDF).\n- Fallback Mechanism Specifications (PDF).\n- Incident Response Plans (PDF).\n- Performance Trend Analysis Reports (Excel).",
      "Control test plan and procedures": "- Execute standard robustness test suite on all systems.\n- Perform adversarial testing on 3 critical systems.\n- Review data quality metrics for last 6 months.\n- Test fallback mechanisms under various failure scenarios.\n- Verify monitoring systems capture performance degradation.\n- Review boundary condition handling in 5 test cases.\n- Control passes if systems maintain performance under all test conditions; fails if any critical vulnerability is found."
    },
    {
      Domain: "Safe Responsible AI",
      Master: "RS-4",
      Topic: "Explainability and Interpretability",
      "Control Statement": "The organisation shall ensure AI systems' decisions and outputs can be appropriately explained and interpreted by relevant stakeholders. This includes maintaining comprehensive documentation of system behaviour, providing clear explanations of AI-driven decisions when required, and ensuring transparency about system capabilities and limitations. Methods for generating explanations must be appropriate to the context and audience.",
      ISO42001: "A.5.3",
      ISO27001: null,
      ISO27701: "7.2.1",
      "EU AI ACT": "50.2 50.3 50.4 50.5",
      "NIST RMF": "Govern 4.2 Map 2.2 Map 2.3 Measure 2.8",
      SOC2: "CC2.2 CC2.3",
      "Key control activities": "- Implementation of explainability tools for AI decisions.\n- Regular review of explanation quality and comprehensibility.\n- Documentation of system logic and decision criteria.\n- Training for staff on explaining AI decisions to stakeholders.\n- Regular updates to explanation methods based on feedback.\n- Maintenance of system capability documentation.\n- Regular assessment of explanation effectiveness.",
      "Required Evidence": "- Explainability Method Documentation (PDF).\n- Decision Explanation Logs (Excel).\n- System Logic Documentation (PDF).\n- Training Materials for Staff (PDF).\n- Stakeholder Feedback Reports (Excel).\n- Capability Documentation (PDF).\n- Explanation Quality Assessment Reports (PDF).\n- User Understanding Test Results (Excel).",
      "Control test plan and procedures": "- Review explanation quality for 10 random decisions.\n- Verify documentation completeness for all systems.\n- Test explanation tools on 5 complex decisions.\n- Survey stakeholders on explanation clarity.\n- Review staff training completion records.\n- Assess explanation consistency across similar cases.\n- Control passes if explanations are clear and accurate; fails if stakeholders cannot understand decisions."
    },
    {
      Domain: "Safe Responsible AI",
      Master: "RS-5",
      Topic: "Fairness and Bias Management",
      "Control Statement": "The organisation shall implement processes to identify, assess, and mitigate unfair bias in AI systems throughout their lifecycle. This includes ensuring training data is representative and appropriate, regularly testing for disparate impact across protected characteristics, and maintaining documented evidence of fairness assessments and mitigation measures. The organisation must regularly validate that AI systems maintain fairness standards in operation.",
      ISO42001: "A.5.4",
      ISO27001: null,
      ISO27701: "7.2.6",
      "EU AI ACT": "5.1 26.4",
      "NIST RMF": "Measure 2.11 Govern 5.2 Measure 2.2",
      SOC2: "CC1.3 CC5.3",
      "Key control activities": "- Regular fairness assessments of AI system outputs.\n- Bias testing across protected characteristics.\n- Data representativeness analysis for training sets.\n- Implementation of bias mitigation techniques.\n- Continuous monitoring of fairness metrics.\n- Regular updates to fairness measures based on assessments.\n- Documentation of bias incidents and resolutions.",
      "Required Evidence": "- Fairness Assessment Reports (PDF).\n- Bias Test Results (Excel).\n- Data Representativeness Analysis (PDF).\n- Bias Mitigation Documentation (PDF).\n- Fairness Monitoring Logs (Excel).\n- Incident Resolution Reports (PDF).\n- Training Data Audit Reports (Excel).\n- Fairness Metric Trending Reports (PDF).",
      "Control test plan and procedures": "- Review fairness metrics for last 6 months.\n- Test for bias across all protected characteristics.\n- Verify data representativeness in training sets.\n- Review effectiveness of bias mitigation measures.\n- Audit fairness monitoring systems.\n- Sample 10 decisions for fairness compliance.\n- Control passes if no significant bias is detected; fails if any protected group is disadvantaged."
    },
    {
      Domain: "Privacy",
      Master: "PR-1",
      Topic: "Privacy by Design and Governance",
      "Control Statement": "The organisation shall implement privacy by design principles in all AI systems, ensuring privacy considerations are embedded from initial planning through system retirement. This includes establishing and maintaining comprehensive privacy policies, conducting privacy impact assessments, defining clear privacy roles and responsibilities, and integrating privacy requirements into project management processes. The organisation shall establish privacy governance structures, maintain documentation of privacy decisions, regularly review privacy controls for effectiveness, and ensure special categories of personal data are processed only when strictly necessary and with appropriate safeguards. Senior management shall demonstrate commitment to privacy through resource allocation and oversight of privacy initiatives.",
      ISO42001: null,
      ISO27001: null,
      ISO27701: "6.1.1 6.1.2 6.2.1-6.2.4 7.2.1-7.2.3 7.2.5 7.2.7 12.2.1 A.7.4.1-A.7.4.9 B.8.4",
      "EU AI ACT": "10.5 26.9 27.4",
      "NIST RMF": null,
      SOC2: "P1.1 P1.2 P1.3",
      "Key control activities": "- Before project initiation, the Privacy Officer conducts a Privacy Impact Assessment using the approved PIA template\n- Quarterly, the Privacy Governance Committee reviews privacy initiatives using the Privacy Program Dashboard\n- For each system design, the Privacy Engineer verifies privacy requirements using the Privacy Requirements Checklist\n- Monthly, the Data Protection Officer reviews privacy controls using the Privacy Control Assessment Tool\n- Annually, the Privacy Audit team conducts a comprehensive privacy audit using the Privacy Audit Framework",
      "Required Evidence": "- Privacy Impact Assessment reports with findings and recommendations (PDF)\n- Privacy Program Dashboard reports showing initiative status (PDF)\n- Privacy Requirements Verification records for all system designs (Excel)\n- Monthly Privacy Control Assessment reports (PDF)\n- Annual Privacy Audit reports with findings and remediation plans (PDF)\n- Privacy policy documentation with review history (PDF)\n- Privacy role assignments and responsibilities matrix (Excel)\n- Privacy training completion records (PDF)",
      "Control test plan and procedures": "- Review Privacy Impact Assessments for all new projects\n- Verify quarterly privacy initiative reviews are conducted\n- Check privacy requirements verification for system designs\n- Review monthly privacy control assessments\n- Examine annual privacy audit results and remediation\n- Verify privacy documentation is complete and current\n- Control passes if privacy controls are effective; fails if significant gaps exist."
    },
    {
      Domain: "Privacy",
      Master: "PR-2",
      Topic: "Personal Data Management",
      "Control Statement": "The organisation shall implement operational processes for the responsible collection, use, storage, and disposal of personal data in AI systems. This includes maintaining data inventories, implementing data classification schemes, managing data retention schedules, and ensuring appropriate data handling throughout the information lifecycle. The organisation shall obtain and maintain records of consent for data processing, provide individuals with access to their data, implement processes for handling data subject requests, and ensure data quality standards are maintained. Clear procedures for data minimisation, purpose limitation, and secure disposal shall be established and followed.",
      ISO42001: null,
      ISO27001: null,
      ISO27701: "8.2.1-8.2.4 8.3.1-8.3.3 A.7.2.1-A.7.2.8 A.7.3.1-A.7.3.10 7.4.5 A.7.5.1-A.7.5.4 B.8.2 B.8.3 B.8.4.2 B.8.5",
      "EU AI ACT": null,
      "NIST RMF": null,
      SOC2: "P2.1 P2.2 P3.1-P3.3 P4.1-P4.3",
      "Key control activities": "- Regular updates to data inventory and classification.\n- Implementation of data retention schedules.\n- Management of consent records and preferences.\n- Processing of data subject access requests.\n- Regular data quality assessments.\n- Implementation of data minimization practices.\n- Secure data disposal procedures.",
      "Required Evidence": "- Data Inventory and Classification Records (Excel).\n- Consent Management Logs (Excel).\n- Data Subject Request Records (Excel).\n- Data Quality Assessment Reports (PDF).\n- Data Retention Schedule (PDF).\n- Data Disposal Certificates (PDF).\n- Data Processing Records (Excel).\n- Data Minimization Review Reports (PDF).",
      "Control test plan and procedures": "- Review data inventory completeness and accuracy.\n- Verify consent records for sample of processing activities.\n- Test data subject request handling process.\n- Check data retention implementation.\n- Verify secure disposal procedures.\n- Assess data minimization effectiveness.\n- Control passes if all data management processes are followed; fails if any personal data is mishandled."
    },
    {
      Domain: "Privacy",
      Master: "PR-3",
      Topic: "Privacy Compliance and Monitoring",
      "Control Statement": "The organisation shall establish processes to monitor compliance with privacy requirements, detect and respond to privacy incidents, and ensure continuous improvement of privacy controls. This includes conducting regular privacy audits, monitoring data processing activities, managing privacy incidents, ensuring supplier compliance with privacy requirements, and maintaining business continuity plans that address privacy considerations. The organisation shall implement privacy metrics, conduct regular assessments, comply with breach notification requirements, and demonstrate ongoing compliance with applicable privacy regulations through documented evidence.",
      ISO42001: null,
      ISO27001: null,
      ISO27701: "12.2.2 15.2.1 16.2.1 16.2.2 17.2.1 18.2.1 18.2.2 A.7.2.5-A.7.2.7 A.7.3.6 B.8.2.4 B.8.2.5",
      "EU AI ACT": null,
      "NIST RMF": null,
      SOC2: "P6.1 P6.2 P6.3 P6.4 P6.5",
      "Key control activities": "- Regular privacy compliance audits.\n- Continuous monitoring of data processing activities.\n- Privacy incident response procedures.\n- Supplier privacy compliance assessments.\n- Privacy metrics tracking and reporting.\n- Privacy breach notification procedures.\n- Regular privacy control assessments.",
      "Required Evidence": "- Privacy Audit Reports (PDF).\n- Privacy Monitoring Logs (Excel).\n- Incident Response Records (PDF).\n- Supplier Assessment Reports (PDF).\n- Privacy Metrics Dashboard (Excel).\n- Breach Notification Records (PDF).\n- Privacy Control Assessment Reports (PDF).\n- Compliance Documentation (PDF).",
      "Control test plan and procedures": "- Review last privacy audit findings and remediation.\n- Test incident response procedures.\n- Verify supplier compliance monitoring.\n- Check privacy metrics tracking.\n- Review breach notification process.\n- Assess privacy control effectiveness.\n- Control passes if compliance is maintained; fails if any privacy requirements are not met."
    },
    {
      Domain: "Privacy",
      Master: "PR-4",
      Topic: "Privacy-Enhancing Technologies and Mechanisms",
      "Control Statement": "The organisation shall implement appropriate technical mechanisms and privacy-enhancing technologies in AI systems to protect personal data and ensure privacy by default. This includes implementing encryption for data at rest and in transit, role-based access control mechanisms, data minimisation techniques, anonymisation and pseudonymisation methods, and secure deletion capabilities. The organisation shall ensure these mechanisms are appropriate for the sensitivity of the data, regularly tested for effectiveness, and updated as privacy-enhancing technologies evolve. This includes how technical controls are documented, validated, and integrated into the system architecture to provide defense in depth for privacy protection.",
      ISO42001: null,
      ISO27001: null,
      ISO27701: "9.2.1-9.2.4 10.2.1-10.2.2 11.2.1-11.2.2 13.2.1 14.2.1-14.2.2 A.7.4.5 A.7.4.9 B.8.4.3",
      "EU AI ACT": null,
      "NIST RMF": null,
      SOC2: "P5.1 P5.2 P5.3 P5.4 P5.5 P5.6",
      "Key control activities": "- Implementation of encryption standards.\n- Role-based access control deployment.\n- Data minimization techniques implementation.\n- Regular testing of privacy mechanisms.\n- Documentation of technical controls.\n- Updates to privacy-enhancing technologies.\n- Integration of privacy controls in architecture.",
      "Required Evidence": "- Encryption Implementation Records (PDF).\n- Access Control Matrix (Excel).\n- Privacy Mechanism Test Results (PDF).\n- Technical Control Documentation (PDF).\n- Architecture Review Reports (PDF).\n- Technology Update Logs (Excel).\n- Security Configuration Standards (PDF).\n- Effectiveness Test Reports (PDF).",
      "Control test plan and procedures": "- Verify encryption implementation.\n- Test access control effectiveness.\n- Review data minimization techniques.\n- Check privacy mechanism testing.\n- Assess technical documentation.\n- Verify architecture integration.\n- Control passes if all technical controls are effective; fails if any privacy mechanism is compromised."
    },
    {
      Domain: "Assurance and Audit",
      Master: "AA-1",
      Topic: "Internal Assessment & Audit",
      "Control Statement": "The organisation shall establish and maintain comprehensive internal assessment and audit procedures for AI systems throughout their lifecycle. This includes documented verification of controls and validation of system behavior in both controlled and real-world conditions. Internal audits must evaluate compliance with organisational policies and procedures. Internal assessment and audit activities must cover normal operations, edge cases, and stress conditions. The organisation shall maintain evidence of all audit activities, findings, and remediation efforts.",
      ISO42001: "9.1 9.2 9.3 A.6.2.4",
      ISO27001: "9.1 9.2 9.3 A.18.2",
      ISO27701: "8.2.3 18.2.2 A.7.2.5 A.7.4.3",
      "EU AI ACT": "9.7-9.8 17.1-17.2 60.1-60.9 61.1 61.2",
      "NIST RMF": "Map 2.3 Measure 2.1 Measure 2.3 Measure 2.5",
      SOC2: "PI1.1 PI1.2 CC4.1",
      "Key control activities": "- Annual internal audit program execution.\n- Quarterly control assessments.\n- Regular system behavior validation.\n- Documentation of audit findings and recommendations.\n- Tracking of remediation activities.\n- Verification of control effectiveness.\n- Regular updates to audit procedures.",
      "Required Evidence": "- Internal Audit Reports (PDF).\n- Control Assessment Records (Excel).\n- System Validation Results (PDF).\n- Audit Finding Logs (Excel).\n- Remediation Tracking Records (Excel).\n- Control Effectiveness Reports (PDF).\n- Audit Program Documentation (PDF).\n- Assessment Methodology Documents (PDF).",
      "Control test plan and procedures": "- Review annual audit program coverage.\n- Verify completion of quarterly assessments.\n- Check system validation documentation.\n- Review remediation of audit findings.\n- Assess control effectiveness measures.\n- Verify audit procedure updates.\n- Control passes if audit program is comprehensive and effective; fails if significant gaps exist."
    },
    {
      Domain: "Assurance and Audit",
      Master: "AA-2",
      Topic: "Independent Assessment and Certification",
      "Control Statement": "The organisation shall ensure regular independent assessments of AI systems are conducted and maintain necessary certifications. Independent assessors must have appropriate expertise and authority to evaluate compliance with regulatory requirements and performance standards. The organisation shall obtain and maintain required certifications, track certification status, and implement corrective actions when gaps are identified. Assessment and certification activities must be documented, including findings and evidence of remediation.",
      ISO42001: "9.1 9.3 10.1 10.2",
      ISO27001: "9.1 9.3 10.1 10.2 A.18.1 A.18.2",
      ISO27701: "7.2.1",
      "EU AI ACT": "20.1 22.3-22.4 40.1 43.1-43.4 44.2 44.3",
      "NIST RMF": "Measure 1.3 Measure 4.2 Govern 4.3",
      SOC2: "CC4.2 CC3.1",
      "Key control activities": "- Selection and engagement of qualified assessors.\n- Coordination of independent assessments.\n- Maintenance of certification requirements.\n- Implementation of corrective actions.\n- Tracking of certification status.\n- Documentation of assessment results.\n- Regular review of certification needs.",
      "Required Evidence": "- Independent Assessment Reports (PDF).\n- Certification Records (PDF).\n- Assessor Qualification Documents (PDF).\n- Corrective Action Plans (Excel).\n- Certification Status Tracker (Excel).\n- Assessment Finding Logs (Excel).\n- Remediation Evidence (PDF).\n- Certification Review Reports (PDF).",
      "Control test plan and procedures": "- Verify assessor qualifications.\n- Review assessment scope and methodology.\n- Check certification status and validity.\n- Track corrective action implementation.\n- Verify assessment documentation.\n- Review certification maintenance.\n- Control passes if assessments are properly conducted and certifications maintained; fails if requirements not met."
    },
    {
      Domain: "Assurance and Audit",
      Master: "AA-3",
      Topic: "Safety and Security Validation",
      "Control Statement": "The organisation shall conduct regular testing of AI system safety and security controls, including assessment of cybersecurity measures, resilience against attacks, and ability to fail safely. Testing must verify that systems operate within defined risk tolerances and maintain effectiveness of protective controls. Validation must include both automated testing and expert review of safety measures. The organisation shall maintain documentation of all safety and security assessments, including methodology, results, and remediation of identified issues.",
      ISO42001: "9.1 9.3",
      ISO27001: "9.1 9.3 A.18.1 A.18.2",
      ISO27701: "7.2.5",
      "EU AI ACT": "41.1-41.2 42.1-42.2",
      "NIST RMF": "Measure 2.6 Measure 2.7",
      SOC2: "CC7.1",
      "Key control activities": "- Regular testing of safety and security controls.\n- Assessment of cybersecurity measures.\n- Validation of system resilience.\n- Testing of fail-safe mechanisms.\n- Documentation of test methodologies.\n- Review of test results by experts.\n- Implementation of remediation measures.",
      "Required Evidence": "- Safety and Security Test Reports (PDF).\n- Cybersecurity Assessment Results (PDF).\n- Resilience Test Documentation (PDF).\n- Fail-safe Test Results (PDF).\n- Test Methodology Documents (PDF).\n- Expert Review Records (PDF).\n- Remediation Tracking Logs (Excel).\n- Validation Summary Reports (PDF).",
      "Control test plan and procedures": "- Review safety and security test coverage.\n- Verify cybersecurity assessment completion.\n- Test system resilience measures.\n- Validate fail-safe mechanisms.\n- Check test methodology documentation.\n- Review expert assessments.\n- Control passes if all validation activities are complete and effective; fails if any critical gaps identified."
    },
    {
      Domain: "Operational Monitoring",
      Master: "OM-1",
      Topic: "System Performance Monitoring",
      "Control Statement": "The organisation shall implement continuous monitoring of AI system performance and behavior in production environments. This includes automated monitoring of key performance indicators, tracking of system outputs, detection of anomalies or degradation in performance, and validation that systems operate within defined parameters. The organisation must maintain documentation of monitoring results, performance trends, and actions taken to address identified issues. Monitoring activities shall be proportional to the system's risk level and complexity.",
      ISO42001: "8.1-8.3 A.6.2.6",
      ISO27001: "8.1-8.3 A.12.3 A.12.6 A.17.1 A.17.2",
      ISO27701: "12.2.2 A.7.4.3",
      "EU AI ACT": "26.5 72.1 72.2 72.3 72.4",
      "NIST RMF": "Measure 1.2 Measure 2.4 Manage 2.2 Manage 2.4",
      SOC2: "CC4.1 CC4.2 A1.1 A1.2",
      "Key control activities": "- Implementation of automated monitoring systems.\n- Regular review of performance metrics.\n- Anomaly detection and alerting.\n- Performance trend analysis.\n- Documentation of monitoring findings.\n- Calibration of monitoring thresholds.\n- Regular validation of monitoring effectiveness.",
      "Required Evidence": "- System Performance Reports (PDF).\n- Monitoring Dashboard Screenshots (PDF).\n- Alert Logs (Excel).\n- Performance Trend Analysis (PDF).\n- Issue Resolution Records (Excel).\n- Monitoring Configuration Documents (PDF).\n- Threshold Review Reports (PDF).\n- Validation Test Results (Excel).",
      "Control test plan and procedures": "- Verify monitoring system coverage.\n- Review performance metric tracking.\n- Test anomaly detection capabilities.\n- Check alert response procedures.\n- Validate monitoring thresholds.\n- Review trend analysis process.\n- Control passes if monitoring is effective and issues are detected; fails if significant issues are missed."
    },
    {
      Domain: "Operational Monitoring",
      Master: "OM-2",
      Topic: "Event Logging",
      "Control Statement": "The organisation shall maintain comprehensive logs of AI system events and operations throughout their lifecycle. Logging systems must capture relevant operational data including system usage, input data references, and verification of results. Logs must be retained for required retention periods, protected from unauthorised access or modification, and made available to authorities when required. The organisation shall ensure logging systems enable effective compliance verification and support incident investigations.",
      ISO42001: "A.6.2.8",
      ISO27001: "A.12.6 A.12.7",
      ISO27701: "12.2.2",
      "EU AI ACT": "12.1-12.3 19.1-19.2 21.2 26.6",
      "NIST RMF": "Govern 4.3",
      SOC2: "CC7.2 CC7.3",
      "Key control activities": "- Daily, the Operations team reviews system alerts using the Monitoring Dashboard\n- Weekly, the Performance Analyst reviews performance metrics using the Performance Monitoring Tool\n- For high-risk AI systems, the Monitoring Specialist conducts daily in-depth reviews using the Critical System Monitoring Checklist\n- Monthly, the AI Operations Manager reviews monitoring effectiveness using the Monitoring Effectiveness Report\n- Quarterly, the Monitoring Governance Committee reviews monitoring strategy using the Monitoring Strategy Review Framework",
      "Required Evidence": "- Daily System Alert Review logs (System logs)\n- Weekly Performance Metrics Review reports (PDF format)\n- Daily Critical System Monitoring Checklists for high-risk systems (PDF format)\n- Monthly Monitoring Effectiveness reports (PDF format)\n- Quarterly Monitoring Strategy Review reports (PDF format)\n- Monitoring configuration documentation (Word documents)\n- Alert threshold documentation with justification (Excel format)",
      "Control test plan and procedures": "- Verify logging system configuration.\n- Review log retention implementation.\n- Test log access controls.\n- Check log integrity measures.\n- Verify incident investigation capability.\n- Review compliance reporting.\n- Control passes if logging is comprehensive and secure; fails if logs are incomplete or compromised."
    },
    {
      Domain: "Operational Monitoring",
      Master: "OM-3",
      Topic: "Continuous Improvement",
      "Control Statement": "The organisation shall establish and maintain a systematic approach to continuous improvement of AI systems throughout their operational lifecycle. This includes implementing processes to gather and analyse performance data, user feedback, and operational metrics to identify opportunities for enhancement. The organisation shall maintain documented improvement plans that outline specific objectives, timelines, and success criteria. Regular reviews must be conducted to evaluate the effectiveness of improvements and identify new areas for optimisation. The organisation shall ensure that improvement initiatives are prioritised based on operational impact and risk considerations, with clear processes for implementing and validating changes.",
      ISO42001: "9.1 10.1 10.2 A.10.4",
      ISO27001: "9.1 10.1 10.2 A.18.2 A.15.2 A.12.6 A.18.1",
      ISO27701: "A.7.4.3 A.7.3.6",
      "EU AI ACT": "17.1 72.1 72.2 72.3 72.4",
      "NIST RMF": "Manage 4.1 Manage 4.2",
      SOC2: "CC3.3 A1.3",
      "Key control activities": "- Regular performance review meetings.\n- Collection and analysis of improvement data.\n- Development of improvement plans.\n- Implementation of approved changes.\n- Validation of improvements.\n- Documentation of lessons learned.\n- Regular stakeholder feedback collection.",
      "Required Evidence": "- Improvement Planning Documents (PDF).\n- Performance Analysis Reports (PDF).\n- Change Implementation Records (Excel).\n- Validation Test Results (PDF).\n- Stakeholder Feedback Logs (Excel).\n- Lessons Learned Repository (PDF).\n- Success Metrics Reports (Excel).\n- Review Meeting Minutes (PDF).",
      "Control test plan and procedures": "- Review improvement planning process.\n- Verify data collection methods.\n- Check implementation tracking.\n- Validate improvement effectiveness.\n- Review stakeholder feedback.\n- Assess lessons learned process.\n- Control passes if improvements are effective and documented; fails if changes don't meet objectives."
    },
    {
      Domain: "Third Party & Supply Chain",
      Master: "TP-1",
      Topic: "Third-Party Provider Responsibilities",
      "Control Statement": "The organisation shall establish clear accountability for AI systems when working with third parties, distributors, importers, or suppliers. This includes documenting responsibilities when AI systems are modified or repurposed, ensuring proper handover of obligations between parties, and maintaining evidence of agreed responsibilities. The organisation must obtain necessary information and technical access from third-party suppliers to ensure regulatory compliance, while respecting confidentiality and intellectual property rights.",
      ISO42001: "A.10.2",
      ISO27001: "A.15.1",
      ISO27701: "15.2.1 A.7.2.6-A.7.2.7 B.8.5.6-B.8.5.8",
      "EU AI ACT": "25.1 25.2 25.3 25.4",
      "NIST RMF": "Map 4.1 Govern 6.1",
      SOC2: "CC2.3",
      "Key control activities": "- Documentation of third-party responsibilities.\n- Regular review of supplier agreements.\n- Monitoring of supplier compliance.\n- Management of handover processes.\n- Verification of technical access rights.\n- Protection of intellectual property.\n- Regular communication with suppliers.",
      "Required Evidence": "- Third-Party Agreements (PDF).\n- Responsibility Matrix (Excel).\n- Compliance Monitoring Reports (PDF).\n- Handover Documentation (PDF).\n- Access Rights Register (Excel).\n- IP Protection Records (PDF).\n- Communication Logs (Excel).\n- Supplier Meeting Minutes (PDF).",
      "Control test plan and procedures": "- Review supplier agreement documentation.\n- Verify responsibility assignments.\n- Check compliance monitoring records.\n- Test handover procedures.\n- Verify access rights management.\n- Review IP protection measures.\n- Control passes if responsibilities are clear and managed; fails if accountability gaps exist."
    },
    {
      Domain: "Third Party & Supply Chain",
      Master: "TP-2",
      Topic: "Supplier Risk Management",
      "Control Statement": "The organisation shall implement comprehensive processes to identify, assess, manage, and monitor risks associated with third-party AI suppliers and service providers throughout the engagement lifecycle. This includes evaluating supplier capabilities during selection, establishing security and privacy requirements in supplier agreements, maintaining contingency plans for critical third-party dependencies, and implementing continuous monitoring of supplier performance and compliance. The organisation shall regularly assess supplier adherence to established requirements, including security standards, privacy requirements, and service level agreements. Performance monitoring must include collection and evaluation of feedback, documentation of monitoring results, and implementation of appropriate actions when issues are identified. Regular reviews of supplier risk assessments and performance metrics shall inform decisions about continuing or modifying supplier relationships.",
      ISO42001: "A.10.2",
      ISO27001: "A.15.1 A.15.2",
      ISO27701: "15.2.1 15.2.2",
      "EU AI ACT": "25.1 25.2 25.3 25.4",
      "NIST RMF": "Map 4.1 Govern 6.1",
      SOC2: "CC9.1 CC9.2",
      "Key control activities": "- Regular supplier risk assessments.\n- Performance monitoring and reporting.\n- Security and privacy requirement verification.\n- Contingency planning for critical suppliers.\n- Service level agreement monitoring.\n- Regular supplier reviews.\n- Documentation of risk mitigation measures.",
      "Required Evidence": "- Supplier Risk Assessment Reports (PDF).\n- Performance Monitoring Dashboards (Excel).\n- Security Assessment Results (PDF).\n- Contingency Plans (PDF).\n- SLA Monitoring Reports (Excel).\n- Supplier Review Minutes (PDF).\n- Risk Mitigation Records (Excel).\n- Compliance Verification Reports (PDF).",
      "Control test plan and procedures": "- Review supplier risk assessment process.\n- Verify performance monitoring implementation.\n- Check security requirement compliance.\n- Test contingency plan effectiveness.\n- Review SLA monitoring results.\n- Assess supplier review process.\n- Control passes if risks are effectively managed; fails if significant risks are unaddressed."
    },
    {
      Domain: "Transparency & Communication",
      Master: "CO-1",
      Topic: "AI System Transparency",
      "Control Statement": "The organisation shall ensure AI systems are designed and operated with appropriate transparency, enabling users and affected individuals to understand when they are interacting with AI, how the AI system impacts them, and what the system's capabilities and limitations are. This includes clear marking of AI-generated content, disclosure of automated decision-making, and provision of comprehensive documentation about system performance and intended use. The organisation must maintain accessibility standards in all transparency communications, provide explanations of AI-driven decisions when required by law, and ensure instructions and documentation are clear and accessible to intended audiences.",
      ISO42001: "7.4 A.6.2.7 A.8.2 A.9.3 A.9.4",
      ISO27001: "7.4 A.6.4",
      ISO27701: "A.7.3.2 A.7.3.3 A.7.3.10 B.8.2.3",
      "EU AI ACT": "13.1-13.3 15.3 50.1-50.5 86.1-86.3",
      "NIST RMF": "Map 1.2 Measure 4.1",
      SOC2: "CC2.2",
      "Key control activities": "- Monthly, the UX team reviews AI system interfaces to ensure clear AI disclosure using the Transparency Checklist\n- For each release, the Documentation team updates system capability documentation using the Documentation Template\n- Weekly, the AI Ethics team reviews automated decision explanations using the Explanation Quality Framework\n- Quarterly, the Accessibility team audits transparency communications using the Accessibility Standards Checklist\n- Before deployment, the Product team verifies AI system marking using the AI Disclosure Verification Process",
      "Required Evidence": "- Monthly Interface Review reports with screenshots (PDF format)\n- System Capability Documentation with updates (PDF format)\n- Weekly Decision Explanation Review logs (Excel format)\n- Quarterly Accessibility Audit reports (PDF format)\n- AI Disclosure Verification records (PDF format)\n- User Communication samples (PDF format)\n- Transparency Implementation Guidelines (PDF format)\n- Accessibility Compliance records (Excel format)",
      "Control test plan and procedures": "- Review AI system interfaces for clear disclosure\n- Verify documentation completeness and clarity\n- Test automated decision explanations\n- Check accessibility compliance\n- Validate AI system marking\n- Review user feedback on transparency\n- Control passes if transparency requirements are met; fails if disclosures are unclear or incomplete"
    },
    {
      Domain: "Transparency & Communication",
      Master: "CO-2",
      Topic: "Stakeholder Engagement and Feedback",
      "Control Statement": "The organisation shall implement comprehensive stakeholder engagement processes to collect, evaluate, and respond to feedback about AI system impacts and performance. This includes establishing mechanisms for regular stakeholder consultation, incorporating feedback into system improvements, and maintaining documentation of stakeholder engagement activities. The organisation must consider diverse perspectives, ensure feedback processes are accessible to all affected communities, and demonstrate how stakeholder input influences system development and operation. Regular reporting to stakeholders about system performance, impacts, and improvements must be maintained.",
      ISO42001: "A.3.3 A.8.3 A.8.5 A.10.4",
      ISO27001: "4.2 A.6.4",
      ISO27701: "A.7.3.4 A.7.3.5 A.7.3.9",
      "EU AI ACT": "4.1 26.7 26.11",
      "NIST RMF": "Govern 5.1 Govern 5.2 Map 5.2 Measure 3.3 Measure 4.3",
      SOC2: "CC2.2",
      "Key control activities": "- Monthly, the Stakeholder Relations team conducts feedback sessions using the Stakeholder Engagement Framework\n- Weekly, the Product team reviews user feedback using the Feedback Analysis Tool\n- Quarterly, the AI Impact team assesses system impacts on different communities using the Impact Assessment Template\n- For each major update, the Communications team prepares stakeholder reports using the Performance Report Template\n- Annually, the Engagement team evaluates feedback process effectiveness using the Process Evaluation Framework",
      "Required Evidence": "- Monthly Stakeholder Session reports (PDF format)\n- Weekly Feedback Analysis reports (Excel format)\n- Quarterly Impact Assessment reports (PDF format)\n- Stakeholder Performance Reports (PDF format)\n- Annual Process Evaluation results (PDF format)\n- Stakeholder engagement records (Excel format)\n- Feedback implementation tracking (Excel format)\n- Community impact documentation (PDF format)",
      "Control test plan and procedures": "- Review stakeholder engagement process\n- Verify feedback collection methods\n- Check impact assessments\n- Test feedback implementation\n- Validate reporting mechanisms\n- Review process accessibility\n- Control passes if stakeholder engagement is effective; fails if feedback is not properly collected or addressed"
    },
    {
      Domain: "Incident Management",
      Master: "IM-1",
      Topic: "Incident Detection and Response",
      "Control Statement": "The organisation shall establish and maintain a comprehensive incident management process for AI systems. This process must include mechanisms for detecting incidents, assessing their severity, implementing immediate response measures, and conducting thorough investigations. The organisation shall maintain documented procedures for incident response, ensure adequate resources are available for incident handling, and verify that response teams have appropriate expertise. Response procedures must address both technical and privacy-related incidents, with specific provisions for high-risk AI systems.",
      ISO42001: "A.8.4",
      ISO27001: "A.16.1 A.12.7",
      ISO27701: "16.2.1 A.7.3.7 B.8.5.4",
      "EU AI ACT": 73.6,
      "NIST RMF": "Manage 4.3",
      SOC2: "CC7.4 P6.1 P6.2",
      "Key control activities": "- Daily, the Incident Response team reviews incident alerts using the Incident Detection System.\n- For each incident, the Incident Manager completes the Incident Response Form using the Incident Management Process.\n- Monthly, the Incident Analysis team reviews incident trends using the Incident Analysis Dashboard.\n- Quarterly, the Incident Response team conducts incident response exercises using the Response Testing Protocol.\n- Annually, the AI Governance Committee reviews incident response effectiveness using the Effectiveness Review Framework.",
      "Required Evidence": "- Incident Detection System logs (System logs).\n- Completed Incident Response Forms (PDF format).\n- Monthly Incident Analysis Reports (PDF format).\n- Quarterly Response Exercise Reports (PDF format).\n- Annual Effectiveness Review Reports (PDF format).\n- Incident Response Team training records (LMS reports).\n- Response procedure documentation (Word documents).\n- Incident tracking logs (Excel format).",
      "Control test plan and procedures": "- Review incident detection system effectiveness.\n- Verify incident response form completion.\n- Check incident analysis quality.\n- Test response procedures.\n- Validate team expertise.\n- Review documentation completeness.\n- Control passes if incidents are effectively managed; fails if response is inadequate."
    },
    {
      Domain: "Incident Management",
      Master: "IM-2",
      Topic: "Incident Reporting and Notification",
      "Control Statement": "The organisation shall implement processes for timely reporting of serious incidents to relevant suppliers, customers, authorities, affected individuals, and other stakeholders as required by applicable regulations or internal policy. This includes maintaining clear notification timelines based on incident severity, ensuring completeness and accuracy of incident reports. The organisation must document all notifications and maintain evidence of compliance.",
      ISO42001: "A.8.4",
      ISO27001: "A.16.1 A.16.2",
      ISO27701: "16.2.2 B.8.5.4 B.8.5.5",
      "EU AI ACT": "73.1-73.5 73.9 73.10",
      "NIST RMF": "Manage 4.3",
      SOC2: "P6.3 P6.4",
      "Key control activities": "- Implementation of incident detection tools\n- Establishment of reporting channels\n- Maintenance of incident logs\n- Execution of response procedures\n- Documentation of incident handling\n- Regular review of detection capabilities\n- Testing of escalation procedures",
      "Required Evidence": "- Incident Detection Configurations (PDF)\n- Reporting Channel Documentation (PDF)\n- Incident Logs (Excel)\n- Response Procedure Records (PDF)\n- Handling Documentation (PDF)\n- Detection Review Reports (PDF)\n- Escalation Test Results (PDF)\n- Tool Configuration Records (Excel)",
      "Control test plan and procedures": "- Test incident detection tools\n- Verify reporting channels\n- Review incident log quality\n- Check response procedures\n- Assess documentation completeness\n- Test escalation process\n- Control passes if detection and response are effective; fails if incidents are missed or poorly handled"
    },
    {
      Domain: "Incident Management",
      Master: "IM-3",
      Topic: "Incident Analysis and Improvement",
      "Control Statement": "The organisation shall analyse incidents to identify root causes, assess the effectiveness of response measures, and implement improvements to prevent recurrence. This includes conducting post-incident reviews, documenting lessons learned, updating incident response procedures based on experience, and verifying the effectiveness of corrective actions. The organisation must maintain records of all incident analyses and resulting improvements.",
      ISO42001: "A.8.4",
      ISO27001: "A.16.3",
      ISO27701: "16.2.1",
      "EU AI ACT": 73.6,
      "NIST RMF": "Manage 4.3",
      SOC2: "P6.5",
      "Key control activities": "- After each incident, the Incident Analysis team conducts root cause analysis using the Root Cause Analysis Framework\n- Monthly, the Incident Review Committee reviews incident analyses using the Incident Review Process\n- Quarterly, the AI Safety team analyzes safety incidents using the Safety Incident Analysis Protocol\n- After major incidents, the Post Incident Review team conducts comprehensive reviews using the Major Incident Review Process\n- Annually, the AI Governance Committee reviews incident analysis effectiveness using the Analysis Effectiveness Review",
      "Required Evidence": "- Root Cause Analysis reports for all incidents (PDF format)\n- Monthly Incident Review Committee meeting minutes (PDF format)\n- Quarterly Safety Incident Analysis reports (PDF format)\n- Major Incident Review reports for all major incidents (PDF format)\n- Annual Analysis Effectiveness Review reports (PDF format)\n- Incident analysis methodology documentation (Word documents)\n- Corrective action tracking logs with implementation status (Excel format)\n- Incident analysis team training records (LMS reports)",
      "Control test plan and procedures": "- Review root cause analysis quality.\n- Verify lessons learned documentation.\n- Check improvement implementation.\n- Test corrective actions.\n- Validate analysis methods.\n- Review trending effectiveness.\n- Control passes if improvements prevent recurrence; fails if similar incidents repeat."
    }
  ] as FrameworkControl[]
}; 
{"data":[{
  "Domain" : "Governance & Leadership",
  "Master" : "GL-1",
  "Topic" : "Executive Commitment and Accountability",
  "Control Statement" : "The organisation's executive leadership shall establish, document, and maintain formal accountability for AI governance through approved policies that align with organisational objectives and values. These policies shall be reviewed at planned intervals by executive leadership to ensure continued effectiveness and relevance. Executive leadership shall demonstrate active engagement in AI risk decisions and maintain ultimate accountability for the organisation's AI systems.",
  "ISO42001" : "4.1 5.1 5.2 9.3 A.2.2 A.2.3 A.2.4",
  "ISO27001" : "5.1 5.2 9.3 A.5.1 A.5.2",
  "ISO27701" : "6.1.1 6.1.2",
  "EU AI ACT" : 4.1,
  "NIST RMF" : "Govern 1.1 Govern 2.3 Govern 3.1",
  "SOC2" : "CC.1.1 CC.1.2 CC.1.3 CC.1.4 CC.1.5 CC.5.3",
  "Key control activities" : "- Establish and document an AI governance policy that aligns with organizational objectives and values\n- Review and update the policy at least annually (or as per defined intervals)\n- Ensure executive leadership actively participates in AI risk decisions (e.g., through regular meetings or reviews)\n- Assign ultimate accountability for AI systems to a specific executive role (e.g., Chief AI Officer or equivalent)",
  "Required Evidence" : "- Copies of the approved AI governance policy\n- Records of policy reviews, including dates, reviewers, and changes made\n- Meeting minutes or decision logs showing executive leadership involvement in AI risk decisions\n- Documentation of the assigned accountability (e.g., organizational chart or role description)",
  "Control test plan and procedures" : "- Verify the existence and accessibility of the AI governance policy\n- Check records to confirm policy reviews occur at defined intervals (e.g., annually)\n- Review meeting minutes to ensure executive leadership is actively engaged in AI risk decisions\n- Confirm documentation exists that clearly assigns ultimate accountability for AI systems\n- Ensure the policy includes pass/fail criteria (e.g., compliance with ISO 42001 or EU AI Act) and corrective actions for noncompliance"
},
{
  "Domain" : "Governance & Leadership",
  "Master" : "GL-2",
  "Topic" : "Roles, Responsibilities & Resources",
  "Control Statement" : "The organisation shall define, document, and maintain clear roles and responsibilities for AI governance, ensuring appropriate segregation of duties and allocation of resources. These roles shall be staffed with competent individuals who understand their responsibilities for AI system development, deployment, and oversight. The organisation shall maintain documentation of required resources, including personnel competencies, tools, and infrastructure needed for effective AI governance.",
  "ISO42001" : "5.3 7.1-7.3 A.3.2 A.4.2",
  "ISO27001" : "5.3 7.1-7.3 A.6.1 A.6.2 A.7.2",
  "ISO27701" : "6.2.1 6.2.2 7.2.2 9.2.3",
  "EU AI ACT" : "22.1 22.2 26.3",
  "NIST RMF" : null,
  "SOC2" : "CC.1.3 CC.1.4",
  "Key control activities" : "Define and document roles and responsibilities for AI governance, including segregation of duties (e.g., development, deployment, oversight). - Ensure roles are staffed with competent individuals (e.g., through skills assessment or training). - Document required resources, including personnel competencies, tools, and infrastructure. - Review and update roles, responsibilities, and resource documentation annually.",
  "Required Evidence" : "Organizational charts or role descriptions outlining AI governance roles and responsibilities. - Job descriptions or competency matrices for AI governance personnel. - Records of resource allocation (e.g., budgets, procurement documents for tools and infrastructure). - Documentation of annual reviews of roles, responsibilities, and resources.",
  "Control test plan and procedures" : "Verify that roles and responsibilities are clearly documented and aligned with segregation of duties. - Check that personnel have the required competencies (e.g., through training records or certifications). - Review resource allocation records to ensure tools and infrastructure are adequately provided. - Confirm annual reviews are conducted and documented. - Ensure the documentation includes specific indicators for pass/fail (e.g., all roles filled by competent personnel) and corrective actions (e.g., retraining or reallocation)."
},
{
  "Domain" : "Governance & Leadership",
  "Master" : "GL-3",
  "Topic" : "Strategic Alignment & Objectives",
  "Control Statement" : "The organisation shall document clear objectives for the responsible development and use of AI systems, ensuring alignment between business goals, ethical principles, and regulatory requirements. These objectives shall be integrated into organisational practices and regularly reviewed to maintain effectiveness. The organisation shall foster an environment that promotes critical thinking and safety-first approaches to AI development and deployment.",
  "ISO42001" : "4.1-4.4 5.2 6.2-6.3 A.2.2-A.2.4 A.6.1.2 A.9.3 A.9.4",
  "ISO27001" : "4.1-4.4 6.2-6.3",
  "ISO27701" : "A.7.2.1 A.7.2.2 B.8.2.2",
  "EU AI ACT" : null,
  "NIST RMF" : "Map 1.3 Map 1.4 Govern 1.1 Govern 1.2 Govern 4.1 Govern 3.1",
  "SOC2" : null,
  " Key control activities" : "Document AI objectives that align with business goals, ethical principles, and regulatory requirements (e.g., ISO 42001, EU AI Act). - Integrate these objectives into organizational practices (e.g., through policies, training, or workflows). - Review and update objectives at least annually to ensure relevance and effectiveness. - Implement initiatives to promote critical thinking and safety-first approaches (e.g., training programs or ethical AI workshops).",
  "Required Evidence" : "Documentation of AI objectives, showing alignment with business goals, ethics, and regulations. - Records of how objectives are integrated into practices (e.g., policy documents, training materials). - Minutes from annual review meetings of AI objectives. - Evidence of initiatives promoting critical thinking and safety (e.g., training session records, workshop agendas).",
  "Control test plan and procedures" : "Verify that AI objectives are documented and aligned with business goals, ethics, and regulations. - Check that objectives are integrated into organizational practices (e.g., through policy references or training logs). - Review records to confirm annual reviews of objectives. - Assess whether initiatives for critical thinking and safety are in place and effective (e.g., through participant feedback or outcome metrics). - Ensure documentation includes pass/fail criteria (e.g., objectives met or not) and corrective actions (e.g., revising objectives or retraining staff)."
},
{
  "Domain" : "Risk Management",
  "Master" : "RM-1",
  "Topic" : "Risk Management Framework and Governance",
  "Control Statement" : "The organisation shall establish, document, and maintain a comprehensive risk management system covering the entire AI lifecycle. This system shall define clear roles, responsibilities, and processes for identifying, assessing, treating, and monitoring AI-related risks. The framework shall incorporate regular reviews by executive leadership and ensure risk management activities align with organisational risk tolerance. Risk management processes shall be transparent, documented, and appropriately resourced to maintain effectiveness.",
  "ISO42001" : "6.1",
  "ISO27001" : 6.1,
  "ISO27701" : "12.2.1 A.7.2.5 A.7.2.8 B.8.2.6",
  "EU AI ACT" : "9.1 9.2",
  "NIST RMF" : "Govern 1.3 Govern 1.4 Govern 1.5 Map 1.5",
  "SOC2" : "CC3.1",
  " Key control activities" : "Establish and document a comprehensive risk management system covering the entire AI lifecycle. - Define clear roles, responsibilities, and processes for identifying, assessing, treating, and monitoring AI-related risks. - Incorporate regular reviews by executive leadership (e.g., quarterly or annually). - Ensure risk management activities align with organisational risk tolerance. - Make risk management processes transparent, documented, and appropriately resourced (e.g., allocate budget and personnel).",
  "Required Evidence" : "Risk management system documentation (policies, procedures, processes). - Risk registers and assessment reports. - Minutes of executive leadership reviews (e.g., quarterly or annual). - Resource allocation records (e.g., budget approvals, staffing plans). - Storage: Centralized GRC system; Sample size: All current and historical risk-related documents.",
  "Control test plan and procedures" : "Verify the existence and accessibility of the documented risk management system. - Check that roles and responsibilities are clearly defined (e.g., via organizational charts or role descriptions). - Review risk registers and assessment reports to ensure regular updates (e.g., quarterly). - Confirm that executive leadership reviews are held as scheduled (e.g., quarterly or annually). - Ensure alignment with organizational risk tolerance (e.g., through documented risk appetite statements). - Verify that risk management processes are transparent and adequately resourced (e.g., budget and personnel records). - Pass/Fail: All risks identified, assessed, treated, and monitored; corrective actions for gaps (e.g., resource reallocation)."
},
{
  "Domain" : "Risk Management",
  "Master" : "RM-2",
  "Topic" : "Risk Identification and Impact Assessment",
  "Control Statement" : "The organisation shall conduct and document comprehensive impact assessments for AI systems, evaluating potential effects on individuals, groups, and society throughout the system lifecycle. These assessments shall consider fundamental rights, safety implications, environmental impacts, and effects on vulnerable populations. The organisation shall maintain a systematic approach to identifying both existing and emerging risks, including those from third-party components and systems.",
  "ISO42001" : "6.1.1-6.1.2 6.1.4 8.4 A.5.2 A.5.3 A.5.4 A.5.5",
  "ISO27001" : "6.1.2",
  "ISO27701" : "A.7.2.5 A.7.3.10 A.7.4.4",
  "EU AI ACT" : "9.9 27.1",
  "NIST RMF" : "Map 1.1 Map 3.1 Map 3.2 Measure 2.6 Measure 2.7 Measure 2.8 Measure 2.10 Measure 2.12",
  "SOC2" : "CC3.2",
  " Key control activities" : "Conduct and document comprehensive impact assessments for AI systems throughout their lifecycle (e.g., pre-deployment, post-deployment, and annually). - Assess potential effects on individuals, groups, and society, including fundamental rights, safety, environmental impacts, and vulnerable populations. - Maintain a systematic approach to identifying both existing and emerging risks, including from third-party components (e.g., via vendor risk assessments). - Review and update impact assessments annually or when significant changes occur.",
  "Required Evidence" : "Impact assessment reports, including methodologies, findings, and mitigation strategies. - Documentation of risk identification processes (e.g., risk matrices or heatmaps). - Records of third-party risk assessments (e.g., vendor due diligence reports). - Storage: GRC system; Sample size: All AI systems' impact assessments for the current year and past three years.",
  "Control test plan and procedures" : "Verify that impact assessments are conducted for all AI systems as required (e.g., pre-deployment and annually). - Review assessment reports to ensure they cover all necessary aspects (e.g., individuals, groups, society, fundamental rights, safety, environment, vulnerable populations). - Check that systematic risk identification processes are in place (e.g., documented methodologies for risk discovery). - Confirm that third-party risks are assessed (e.g., via vendor questionnaires or audits). - Ensure assessments are reviewed and updated as required (e.g., annually or upon system changes). - Pass/Fail: All required assessments completed; corrective actions for incomplete or inadequate assessments (e.g., reassessment or system adjustments)."
},
{
  "Domain" : "Risk Management",
  "Master" : "RM-3",
  "Topic" : "Risk Treatment and Control Implementation",
  "Control Statement" : "The organisation shall implement appropriate technical and organisational measures to address identified risks, ensuring controls are proportionate to risk levels and organisational risk tolerance. Risk treatment strategies shall be documented and prioritised based on impact and likelihood, with clear accountability for implementation. The organisation shall maintain specific protocols for high-risk AI systems, including quality management systems and compliance verification processes.",
  "ISO42001" : "6.1.3",
  "ISO27001" : "6.1.3",
  "ISO27701" : "A.7.4.1 A.7.4.2 A.7.4.4 A.7.4.5",
  "EU AI ACT" : "8.1 8.2 17.1 9.3 9.4 9.5",
  "NIST RMF" : "Manage 1.2 Manage 1.3 Manage 1.4",
  "SOC2" : "CC5.1 CC9.1",
  " Key control activities" : "Implement technical and organizational measures to address identified risks (e.g., data encryption, access controls, training programs). - Ensure controls are proportionate to risk levels and organizational risk tolerance (e.g., high-risk systems require more stringent controls). - Document risk treatment strategies and prioritize based on impact and likelihood (e.g., using a risk matrix). - Assign clear accountability for implementation (e.g., specific roles like AI Risk Officer). - Maintain specific protocols for high-risk AI systems, including quality management systems (e.g., ISO 9001) and compliance verification processes (e.g., third-party audits).",
  "Required Evidence" : "Risk treatment plans and strategies (e.g., documented action plans). - Records of implemented controls (e.g., system configurations, training logs). - Quality management system documentation for high-risk AI systems (e.g., ISO 9001 certification). - Compliance verification reports (e.g., audit reports or self-assessment logs). - Storage: GRC system; Sample size: All risk treatment documentation for current and past year.",
  "Control test plan and procedures" : "Verify that risk treatment measures are implemented as per documented plans. - Check that controls are proportionate to identified risks (e.g., via risk assessment cross-referencing). - Review prioritization of risk treatments based on impact and likelihood (e.g., via risk matrix). - Ensure accountability is clearly assigned (e.g., via role descriptions or accountability matrices). - Confirm that specific protocols for high-risk AI systems are in place (e.g., quality management processes, compliance checks). - Pass/Fail: All identified risks have proportionate treatments; corrective actions for gaps (e.g., additional controls or re-prioritization)."
},
{
  "Domain" : "Risk Management",
  "Master" : "RM-4",
  "Topic" : "Risk Monitoring and Response",
  "Control Statement" : "The organisation shall implement continuous monitoring processes to track the effectiveness of risk controls and identify emerging risks throughout the AI lifecycle. This shall include mechanisms for detecting and responding to previously unknown risks, regular evaluation of third-party risk exposure, and processes for incident response and recovery. The organisation shall maintain documentation of monitoring activities and ensure appropriate escalation paths for risk-related issues.",
  "ISO42001" : "6.1.3 8.1-8.3",
  "ISO27001" : "6.1.3 8.1-8.3",
  "ISO27701" : "A.7.4.3 A.7.4.9 B.8.2.4 B.8.2.5 B.8.4.3",
  "EU AI ACT" : 9.6,
  "NIST RMF" : "Measure 3.1 Measure 3.2 Manage 2.1 Manage 2.2 Manage 2.3 Manage 3.1 Govern 6.1 Govern 6.2",
  "SOC2" : "CC3.4 CC9.2",
  " Key control activities" : "Implement continuous monitoring processes to track the effectiveness of risk controls (e.g., via automated tools or periodic reviews). - Identify emerging risks throughout the AI lifecycle (e.g., through threat intelligence or incident reporting). - Include mechanisms for detecting and responding to previously unknown risks (e.g., anomaly detection systems). - Regularly evaluate third-party risk exposure (e.g., quarterly vendor risk reviews). - Maintain processes for incident response and recovery (e.g., documented incident response plans). - Document monitoring activities and ensure appropriate escalation paths for risk-related issues (e.g., via escalation matrices).",
  "Required Evidence" : "Monitoring reports and logs (e.g., system logs, audit trails). - Incident response and recovery plans (e.g., documented procedures). - Records of third-party risk evaluations (e.g., vendor audit reports). - Documentation of escalation procedures and actions taken (e.g., issue logs). - Storage: GRC system; Sample size: All monitoring and incident records for current year.",
  "Control test plan and procedures" : "Verify that continuous monitoring processes are operational (e.g., via system configurations or tool usage logs). - Review monitoring reports to ensure they cover all required areas (e.g., control effectiveness, emerging risks). - Check that mechanisms for detecting emerging risks are effective (e.g., via threat intelligence reports). - Ensure third-party risks are regularly evaluated (e.g., quarterly reviews). - Confirm that incident response and recovery processes are tested and updated (e.g., via drill records). - Verify that documentation of monitoring activities is complete and accurate (e.g., via audit trails). - Pass/Fail: All monitoring activities are conducted as scheduled; corrective actions for gaps (e.g., process improvements or additional monitoring)."
},
{
  "Domain" : "Regulatory Operations",
  "Master" : "RO-1",
  "Topic" : "Regulatory Compliance Framework",
  "Control Statement" : "The organisation shall establish, document, and maintain a comprehensive framework for ensuring compliance with applicable AI regulations and standards. This framework shall include processes for identifying relevant requirements, assessing applicability, implementing necessary controls, and verifying ongoing compliance. The organisation shall maintain systematic processes for tracking and implementing new regulatory requirements, conducting conformity assessments, maintaining necessary certifications, and ensuring timely renewal of compliance documentation. Special attention shall be given to high-risk AI system requirements and prohibited practices. The organisation shall implement processes to track changes that may affect compliance status and maintain evidence of continued conformity with legal obligations",
  "ISO42001" : null,
  "ISO27001" : "A.18.1",
  "ISO27701" : "18.2.1 A.7.2.1-A.7.2.4 B.8.2.1-B.8.2.2 B.8.2.4-B.8.2.5",
  "EU AI ACT" : "5.1 5.2 6.1-6.4 8.1-8.2 40.1 41.1 42.1 43.1-43.4 44.2-44.3 47.1-47.4 49.1-49.3",
  "NIST RMF" : "Govern 1.1 Map 4.1",
  "SOC2" : "CC1.5",
  " Key control activities" : "• Quarterly, the Compliance Officer reviews regulatory updates from relevant authorities (EU AI Act, NIST, ISO) and updates the compliance tracking register • Monthly, the AI Governance Committee assesses the applicability of new requirements to existing AI systems using the Regulatory Impact Assessment template • Semi-annually, the Compliance team conducts a comprehensive gap analysis against applicable requirements and documents findings in the Compliance Assessment Report • For high-risk AI systems, the AI Product Manager maintains a specific compliance checklist that is reviewed monthly by the Compliance Officer • When new regulations are published, the Legal team analyzes requirements within 30 days and communicates necessary changes to relevant stakeholders",
  "Required Evidence" : "• Compliance Tracking Register documenting all applicable regulations with dates of updates (Excel format) • Regulatory Impact Assessment reports for each new regulatory requirement (PDF format) • Gap Analysis Reports from semi-annual compliance assessments (PDF format) • High-Risk AI System Compliance Checklists for each applicable system (Excel format) • Meeting minutes from AI Governance Committee showing review of regulatory changes (PDF format) • Regulatory notification emails sent to stakeholders with acknowledgment receipts (Email archive) • Documentation of conformity assessments conducted for high-risk AI systems (PDF format) • Certificates and compliance documentation with validity dates and renewal schedules (PDF format)",
  "Control test plan and procedures" : "1 Select the last four quarterly regulatory reviews performed by the Compliance Officer 2 Verify that the Compliance Tracking Register has been updated appropriately with new requirements 3 For three randomly selected regulatory updates, trace through the process to confirm: ◦ Initial assessment was completed within 30 days ◦ Impact analysis was documented using the standard template ◦ Required changes were communicated to appropriate stakeholders ◦ Implementation plans were developed and tracked to completion 4 For high-risk AI systems, verify monthly compliance reviews are conducted by examining the last six months of checklists 5 Select two certification renewals from the past year and confirm they were completed before expiration 6 Control passes if all samples show compliance with established procedures and timelines; fails if any step was missed or significant delays occurred 7 If failure, the Compliance Officer must report to the AI Governance Committee and establish a remediation plan within 10 business days"
},
{
  "Domain" : "Regulatory Operations",
  "Master" : "RO-2",
  "Topic" : "Transparency, Disclosure and Reporting",
  "Control Statement" : "The organisation shall implement mechanisms to ensure appropriate transparency regarding AI systems, including clear notification of AI use, disclosure of automated decision-making, and communication of significant system changes. The organisation shall establish and maintain processes for reporting incidents, safety issues, and non-compliance to relevant authorities and affected stakeholders. This shall include clear procedures for incident detection, assessment, notification timelines, and follow-up actions.",
  "ISO42001" : "A.8.3 A.8.5",
  "ISO27001" : "A.6.3",
  "ISO27701" : "6.2.3 A.7.3.2-A.7.3.3 A.7.3.8-A.7.3.9 A.7.5.3-A.7.5.4 B.8.5.3-B.8.5.6",
  "EU AI ACT" : "50.1-50.5 86.1-86.3 20.1 20.2 60.7 60.8",
  "NIST RMF" : "Govern 6.1 Map 4.1",
  "SOC2" : "CC2.3 P1.1 P1.2 P1.3",
  " Key control activities" : "• Monthly, the AI Product Manager reviews all AI system interfaces to verify appropriate AI disclosure notices using the Transparency Checklist • For each system update, the Development Lead completes the Change Impact Assessment form that includes transparency requirements verification • Quarterly, the UX Designer audits all user touchpoints for clarity of AI notifications using the UX Audit Tool • Before any significant system change, the Product Manager ensures updated disclosure documentation is prepared and approved by Legal • The Communications Manager maintains a stakeholder notification template for system changes that is reviewed annually by Legal and updated as needed",
  "Required Evidence" : "• Completed monthly AI Transparency Checklists for each system (PDF format) • Change Impact Assessment forms showing transparency requirements verification (PDF format) • Quarterly UX Audit reports with screenshots of AI disclosures (PDF format with attachments) • User interface mockups and implemented screens showing AI notifications (Image files) • Legal approval emails for disclosure language (Email archive) • Stakeholder notification templates with revision history (Word documents) • Sample communications sent to users regarding significant system changes (Email archives) • Record of automated decision-making notifications with timestamps (System logs)",
  "Control test plan and procedures" : "1 Select three AI systems and examine the last three monthly Transparency Checklists 2 For each selected system, access the live environment and verify AI disclosures are present, visible, and accurate 3 Review the last five Change Impact Assessments to confirm transparency requirements were evaluated 4 Select two significant system changes from the past six months and verify that: ◦ Disclosure documentation was updated prior to deployment ◦ Legal approval was obtained and documented ◦ Users were notified appropriately about the changes 5 Control passes if all transparency disclosures are present, accurate, and properly communicated; fails if disclosures are missing, inaccurate, or not properly communicated 6 If failure, the AI Product Manager must implement corrections within 5 business days and review all other system interfaces to ensure consistency"
},
{
  "Domain" : "Regulatory Operations",
  "Master" : "RO-3",
  "Topic" : "Record-Keeping",
  "Control Statement" : "The organisation shall maintain comprehensive documentation and records demonstrating compliance with AI regulatory requirements. This shall include technical documentation, conformity assessments, impact analyses, test results, and evidence of ongoing monitoring. The organisation shall establish retention periods aligned with regulatory requirements, implement secure storage systems, and ensure documentation remains accessible to authorised parties throughout required retention periods.",
  "ISO42001" : null,
  "ISO27001" : "A.7.2",
  "ISO27701" : "8.2.3 A.7.2.8 A.7.3.1 A.7.4.3 A.7.4.6-A.7.4.8 B.8.2.6 B.8.4.1-B.8.4.2",
  "EU AI ACT" : "11.1 11.3 18.1 19.1 19.2 71.2 71.3",
  "NIST RMF" : "Map 4.1 Measure 2.12",
  "SOC2" : "P3.1 P3.2 P3.3",
  " Key control activities" : "• Monthly, the Documentation Manager reviews the AI System Documentation Repository to ensure all required documentation is current and compliant • For each system update, the AI Engineer updates technical documentation and submits for review to the Technical Lead within 5 business days • Quarterly, the Compliance Officer conducts a documentation audit using the Documentation Completeness Checklist • Annually, the Records Manager reviews documentation retention policies against regulatory requirements and updates as needed • During system development, the AI Project Manager ensures documentation is created according to the Documentation Standards Guide",
  "Required Evidence" : "• AI System Documentation Repository inventory report showing all documents with last update dates (Excel format) • Technical documentation change logs with approvals (PDF format) • Quarterly Documentation Audit reports with findings and remediation actions (PDF format) • Annual Documentation Retention Policy review documentation (Word document) • Sample of critical AI system documentation (conformity assessments, impact analyses, test results) (Various formats) • Access logs for documentation repository showing appropriate permission controls (System logs) • Documentation Standards Guide with revision history (Word document) • Training records showing staff completion of documentation procedures training (LMS report)",
  "Control test plan and procedures" : "1 Select two AI systems and verify that all required documentation types are present in the repository 2 For each selected system, check that documentation was updated following the last three system changes 3 Review the last two quarterly documentation audits and verify that: ◦ All findings were documented ◦ Remediation actions were assigned ◦ Follow-up verification was completed 4 Select one high-risk AI system and verify retention of all required documentation per regulatory requirements 5 Verify access controls by confirming that only authorized personnel can access, modify, or delete documentation 6 Control passes if documentation is complete, current, and properly secured; fails if documentation is missing, outdated, or improperly managed 7 If failure, the Documentation Manager must create a remediation plan within 5 business days and implement corrections within 30 days"
},
{
  "Domain" : "Regulatory Operations",
  "Master" : "RO-4",
  "Topic" : "Post-Market Monitoring",
  "Control Statement" : "The organisation shall implement comprehensive post-market monitoring systems for deployed AI systems, including mechanisms for tracking performance, identifying issues, and implementing corrective actions. This shall include processes for reporting incidents to relevant authorities, maintaining required documentation, and conducting periodic reviews of system performance. The organisation shall ensure appropriate escalation paths exist for identified issues and maintain clear procedures for implementing necessary corrective actions.",
  "ISO42001" : "A.8.3",
  "ISO27001" : null,
  "ISO27701" : "6.2.3 A.7.3.6-A.7.3.7 A.7.3.10 A.7.4.3 B.8.3.1 B.8.5.7-B.8.5.8",
  "EU AI ACT" : "72.1-72.4 79.4 80.4-80.5",
  "NIST RMF" : "Govern 6.1 Measure 2.12",
  "SOC2" : "CC1.5",
  " Key control activities" : "• Daily, the Operations team reviews automated system monitoring alerts and documents issues in the Incident Management System • Weekly, the AI Performance Analyst reviews performance metrics against established thresholds using the Performance Dashboard • Monthly, the AI Product Manager reviews user feedback related to AI system performance using the Feedback Analysis Report • Quarterly, the AI Governance Committee reviews system performance trends and incident reports using the Quarterly Performance Review template • For high-risk AI systems, the Risk Manager conducts monthly detailed performance reviews against predefined risk thresholds",
  "Required Evidence" : "• Daily system monitoring logs with alert records and resolution documentation (System logs) • Weekly Performance Analysis Reports with metrics, trends, and anomalies identified (PDF format) • Monthly Feedback Analysis Reports with categorized user feedback and actions taken (Excel format) • Quarterly Performance Review reports with committee sign-off (PDF format) • Incident reports with investigation findings, corrective actions, and regulatory notifications when applicable (PDF format) • Post-incident review documentation showing root cause analysis and preventive measures (Word documents) • Regulatory authority notification records where required (Email archives) • Corrective Action implementation records with verification (PDF format)",
  "Control test plan and procedures" : "1 Review the last 30 days of system monitoring logs and verify that alerts were addressed per established procedures 2 Select three performance incidents from the past quarter and trace through the response process to confirm: ◦ Initial detection and logging occurred per procedures ◦ Appropriate escalation took place within required timeframes ◦ Investigation was thorough and well-documented ◦ Corrective actions were implemented and verified ◦ Required notifications were made to authorities (if applicable) 3 Review the last two Quarterly Performance Review reports and verify they were reviewed by the AI Governance Committee 4 For one high-risk AI system, review the last three monthly performance reviews against risk thresholds 5 Control passes if monitoring activities are consistently performed and documented, with appropriate response to identified issues; fails if monitoring is inconsistent or responses inadequate 6 If failure, the AI Operations Manager must immediately review monitoring processes and implement improvements within 15 business days"
},
{
  "Domain" : "System, Data and Model Lifecycle",
  "Master" : "LC-1",
  "Topic" : "Data Quality and Governance",
  "Control Statement" : "The organisation shall establish and maintain comprehensive data governance processes ensuring high-quality data throughout the AI system lifecycle. This shall include documented requirements and procedures for data collection, processing, and validation, ensuring datasets are relevant, representative, and statistically suitable for their intended purpose. The organisation shall implement processes for bias detection and mitigation, maintain clear data provenance records, and ensure data reflects the specific geographical, behavioural, and functional settings where AI systems will be used.",
  "ISO42001" : "A.7.2-A.7.6",
  "ISO27001" : null,
  "ISO27701" : "A.7.4.1-A.7.4.2 A.7.4.6-A.7.4.8 B.8.4.1-B.8.4.2",
  "EU AI ACT" : "10.1-10.6",
  "NIST RMF" : "Map 2.1",
  "SOC2" : null,
  " Key control activities" : "• Before data acquisition, the Data Steward completes the Data Quality Assessment form to verify relevance, representativeness, and statistical suitability • Monthly, the Data Quality Analyst runs the Data Quality Monitoring scripts and documents results in the Data Quality Report • Quarterly, the AI Ethics Officer conducts bias detection tests using the Bias Detection Framework and documents findings • For each training dataset update, the Data Engineer verifies data provenance using the Data Lineage Verification Checklist • Annually, the Data Governance Committee reviews data governance policies against regulatory requirements and updates as needed",
  "Required Evidence" : "• Completed Data Quality Assessment forms for all datasets used in AI systems (PDF format) • Monthly Data Quality Reports showing data validation results (PDF format) • Quarterly Bias Detection Test results with mitigation actions (PDF format) • Data Lineage Documentation showing clear provenance for all datasets (Excel format) • Data Processing Records showing transformation and validation steps (System logs) • Dataset bias assessment reports with mitigation strategies (PDF format) • Geographic and behavioral representation analysis for training datasets (Excel format) • Data validation test results showing statistical suitability (PDF format)",
  "Control test plan and procedures" : "1 Select three datasets used in AI systems and verify completed Data Quality Assessment forms exist 2 For selected datasets, verify documentation demonstrates: ◦ Relevance to intended purpose ◦ Representative of actual usage scenarios ◦ Statistically suitable sample size and distribution 3 Review the last two quarterly bias detection test reports and verify that: ◦ Tests were conducted using approved methodologies ◦ Findings were properly documented ◦ Mitigation actions were implemented and verified 4 For one high-risk AI system, verify complete data provenance documentation exists 5 Control passes if data governance processes are followed consistently with proper documentation; fails if data quality processes are inconsistent or inadequately documented 6 If failure, the Data Governance Manager must implement corrective actions within 10 business days and conduct a comprehensive review of all affected datasets"
},
{
  "Domain" : "System, Data and Model Lifecycle",
  "Master" : "LC-2",
  "Topic" : "System Development and Lifecycle Management",
  "Control Statement" : "The organisation shall define, document, and maintain processes for responsible AI system development across the entire lifecycle, from requirements specification through deployment and eventual decommissioning. The organisation shall maintain clear records of system objectives, technical implementation decisions, and operational constraints throughout development and deployment phases.",
  "ISO42001" : "A.6.1.2-A.6.1.3 A.6.2.2-A.6.2.3 A.6.2.5",
  "ISO27001" : null,
  "ISO27701" : "A.7.4.1-A.7.4.2 A.7.4.5-A.7.4.8 B.8.4.1-B.8.4.2",
  "EU AI ACT" : null,
  "NIST RMF" : "Map 1.6 Govern 1.7",
  "SOC2" : "CC8.1 CC8.2",
  " Key control activities" : "• Before project initiation, the AI Project Manager completes the System Requirements Specification using the approved template • During design phase, the AI Architect creates and updates the System Architecture Document that is reviewed by the Security and Privacy teams • At each development milestone, the AI Engineering Lead conducts a Technical Implementation Review using the Review Checklist • Before deployment, the Quality Assurance Manager performs a final validation using the Pre-Deployment Validation Checklist • Quarterly, the AI Governance Committee reviews a sample of systems to verify lifecycle documentation is complete",
  "Required Evidence" : "• System Requirements Specifications with stakeholder sign-off (PDF format) • System Architecture Documents with Security and Privacy review notes (PDF format) • Technical Implementation Review reports from each development milestone (PDF format) • Pre-Deployment Validation Checklist with sign-off from required stakeholders (PDF format) • Development decision logs documenting key implementation choices (Excel format) • System decommissioning plans for end-of-life systems (Word documents) • Test case documentation and results for system validation (PDF format) • Quarterly AI Governance Committee review reports (PDF format)",
  "Control test plan and procedures" : "1 Select two AI systems developed in the past year and verify that all lifecycle documentation exists: ◦ Requirements Specification ◦ Architecture Document ◦ Technical Implementation Reviews ◦ Pre-Deployment Validation 2 For each selected system, verify that Security and Privacy reviews were conducted and documented 3 Review one system's complete development history to confirm all required approvals were obtained at each phase 4 For a system currently in development, verify active documentation is being maintained according to procedures 5 Control passes if complete lifecycle documentation exists with appropriate approvals; fails if documentation is incomplete or approvals missing 6 If failure, the AI Project Manager must develop a remediation plan within 5 business days and implement corrections within 20 business days"
},
{
  "Domain" : "System, Data and Model Lifecycle",
  "Master" : "LC-3",
  "Topic" : "Resource Management and Infrastructure",
  "Control Statement" : "The organisation shall document and maintain inventories of all resources required for AI system development and operation, including data resources, tooling, computing infrastructure, and human competencies. This shall include clear allocation of responsibilities, documentation of system dependencies, and maintenance of resource specifications throughout the system lifecycle.",
  "ISO42001" : "A.4.3 A.4.5 A.4.6 A.10.2",
  "ISO27001" : "A.8.1 A.8.2",
  "ISO27701" : "A.7.2.6 A.7.2.7 B.8.5.6",
  "EU AI ACT" : null,
  "NIST RMF" : "Govern 1.6",
  "SOC2" : null,
  " Key control activities" : "• Quarterly, the Resource Manager updates the AI Resource Inventory using the Resource Management Tool • Monthly, the AI Engineering Lead reviews resource allocation and utilization using the Resource Utilization Report • Before new AI projects, the Project Manager completes the Resource Requirements Assessment using the approved template • Annually, the Training Manager assesses staff competencies against required skills using the Competency Assessment Framework • When resource dependencies change, the System Owner updates the System Dependency Documentation within 5 business days",
  "Required Evidence" : "• AI Resource Inventory showing data resources, tools, infrastructure, and human competencies (Excel format) • Monthly Resource Utilization Reports with analysis of usage patterns (PDF format) • Resource Requirements Assessments for all new AI projects (PDF format) • Annual Competency Assessment reports with gap analysis (PDF format) • System Dependency Documentation with revision history (Word documents) • Resource allocation meeting minutes showing decision-making (PDF format) • Infrastructure capacity planning documents (PDF format) • Tool license and capacity management records (Excel format)",
  "Control test plan and procedures" : "1 Review the AI Resource Inventory to verify it includes all required resource categories 2 Select two AI systems and verify that resource dependencies are accurately documented 3 Review the last three monthly Resource Utilization Reports to confirm regular monitoring occurs 4 For one new AI project, verify the Resource Requirements Assessment was completed before project initiation 5 Select five employees involved in AI development and verify current Competency Assessments exist 6 Control passes if resource management documentation is complete and up-to-date; fails if documentation is incomplete or outdated 7 If failure, the Resource Manager must update all affected documentation within 15 business days and implement process improvements to prevent recurrence"
},
{
  "Domain" : "System, Data and Model Lifecycle",
  "Master" : "LC-4",
  "Topic" : "Technical Documentation",
  "Control Statement" : "The organisation shall maintain comprehensive technical documentation demonstrating compliance throughout the AI system lifecycle. This shall include system characteristics, design specifications, validation results, and operational logs. The organisation shall implement automated logging mechanisms to capture system events, maintain documentation for required retention periods, and ensure documentation remains accessible to relevant stakeholders.",
  "ISO42001" : "7.5.1-7.5.3 A.6.2.7 A.6.2.8",
  "ISO27001" : "7.5.1-7.5.3",
  "ISO27701" : "A.7.2.8 A.7.5.3 A.7.5.4 B.8.2.6 B.8.5.3",
  "EU AI ACT" : "11.1-11.3 12.1-12.3 18.1",
  "NIST RMF" : "Map 2.2 Map 3.3",
  "SOC2" : null,
  " Key control activities" : "• For each system release, the Technical Writer updates the Technical Documentation Package using the Documentation Checklist • Monthly, the AI Engineer reviews system logs to ensure automated logging is functioning properly • Quarterly, the Documentation Manager conducts a documentation audit using the Documentation Compliance Checklist • Before major version releases, the Quality Assurance team validates technical documentation accuracy using the Documentation Validation Process • When system characteristics change, the System Owner updates the System Specification Document within 10 business days",
  "Required Evidence" : "• Complete Technical Documentation Packages for each system version (PDF format) • Documentation Checklist with sign-off from required stakeholders (PDF format) • Monthly system logging verification reports (PDF format) • Quarterly Documentation Audit reports with findings and remediation (PDF format) • Documentation Validation testing results (PDF format) • System Specification Documents with revision history (Word documents) • System logs showing operational data collection (System logs) • Documentation retention schedule with compliance verification (Excel format)",
  "Control test plan and procedures" : "1 Select two AI systems and verify complete Technical Documentation Packages exist for the current version 2 For each selected system, verify documentation includes: ◦ System characteristics ◦ Design specifications ◦ Validation results ◦ Operational logs 3 Review system logs from the past 30 days to confirm automated logging is functioning properly 4 For one system that underwent changes in the past quarter, verify the System Specification Document was updated appropriately 5 Control passes if technical documentation is complete, accurate, and up-to-date; fails if documentation is incomplete, inaccurate, or outdated 6 If failure, the Documentation Manager must implement corrections within 10 business days and review all system documentation to identify similar issues"
},
{
  "Domain" : "System, Data and Model Lifecycle",
  "Master" : "LC-5",
  "Topic" : "Change Management & Version Control",
  "Control Statement" : "The organisation shall establish and maintain comprehensive processes for managing changes to AI systems throughout their lifecycle. This shall include documented procedures for proposing, evaluating, testing, and implementing changes to models, data, or system components. The organisation shall maintain detailed version control of all system elements, including models, datasets, and software components, with clear records of modifications and their rationale. Changes shall be tested and validated before deployment, with documentation updated to reflect current system state.",
  "ISO42001" : "A.6.2.5",
  "ISO27001" : "A.12.2",
  "ISO27701" : "A.7.3.7 B.8.5.7 B.8.5.8",
  "EU AI ACT" : 11.3,
  "NIST RMF" : "Map 2.1",
  "SOC2" : "CC8.1 CC8.2",
  " Key control activities" : "• For each system change, the Change Manager completes the Change Request Form and obtains approval from the Change Advisory Board • Before implementing changes, the Test Manager verifies test plans using the Change Testing Checklist • After each change implementation, the Quality Assurance team validates the change using the Post-Implementation Verification Process • Monthly, the Version Control Administrator audits version control systems using the Version Control Audit Checklist • Quarterly, the Change Manager reviews change management metrics using the Change Management Dashboard",
  "Required Evidence" : "• Change Request Forms with appropriate approvals for all system changes (PDF format) • Change Advisory Board meeting minutes documenting change approvals (PDF format) • Pre-implementation test plans and results (PDF format) • Post-Implementation Verification reports (PDF format) • Version control system logs showing all component versions (System logs) • Version Control Audit reports (PDF format) • Change Management Dashboard reports showing metrics and trends (PDF format) • Documentation updates reflecting implemented changes (Various formats)",
  "Control test plan and procedures" : "1 Select five system changes from the past quarter and verify for each: ◦ Properly completed Change Request Form exists ◦ Change Advisory Board approval was obtained ◦ Testing was conducted and documented ◦ Post-implementation verification was performed 2 Review the version control system to confirm proper versioning of models, datasets, and code 3 Examine documentation to verify it was updated to reflect the implemented changes 4 Review the last two monthly Version Control Audits to confirm they were conducted properly 5 Control passes if change management procedures are consistently followed with proper documentation; fails if procedures are inconsistently followed or inadequately documented 6 If failure, the Change Manager must implement process improvements within 10 business days and conduct a comprehensive review of recent changes"
},
{
  "Domain" : "Security",
  "Master" : "SE-1",
  "Topic" : "Security Governance, Architecture and Engineering",
  "Control Statement" : "The organisation shall establish and maintain a comprehensive security governance framework that encompasses security risk management, security policies, standards, and architectures that guide the implementation of security controls across the organisation. The organisation shall ensure continuous monitoring of control effectiveness, manages security incidents, and maintains business continuity capabilities while overseeing third-party security requirements.",
  "ISO42001" : null,
  "ISO27001" : "A.5.1-A.5.2 A.6.1-A.6.2 A.6.5 A.7.1-A.7.4 A.12.1-A.12.3 A.17.1-A.17.2 A.18.1-A.18.2",
  "ISO27701" : "14.2.1 14.2.2",
  "EU AI ACT" : null,
  "NIST RMF" : null,
  "SOC2" : "CC2.3 CC3.1 CC3.2 CC5.2 CC7.2 CC7.3 CC9.3",
  " Key control activities" : "• Quarterly, the CISO conducts a Security Risk Assessment using the Security Risk Management Framework • Annually, the Security Policy Manager reviews and updates security policies using the Policy Review Checklist • Monthly, the Security Operations team reviews security control effectiveness using the Security Control Dashboard • Quarterly, the Security Incident Response team tests incident response procedures through tabletop exercises • Annually, the Business Continuity Manager tests and updates the Business Continuity Plan",
  "Required Evidence" : "• Quarterly Security Risk Assessment reports with findings and remediation plans (PDF format) • Annual Security Policy Review documentation with updates and approvals (PDF format) • Monthly Security Control Effectiveness reports (PDF format) • Quarterly Incident Response Exercise reports with lessons learned (PDF format) • Annual Business Continuity Test reports with results and improvements (PDF format) • Security architecture documentation with review history (PDF format) • Third-party security assessment reports (PDF format) • Security governance meeting minutes showing oversight activities (PDF format)",
  "Control test plan and procedures" : "1 Review the last two quarterly Security Risk Assessments to verify they were conducted properly 2 Select three security policies and verify they have been reviewed within the past year 3 Review the last three monthly Security Control Effectiveness reports to confirm regular monitoring 4 Examine the most recent Incident Response Exercise report to verify testing of procedures 5 Review the Business Continuity Plan to confirm it has been tested and updated within the past year 6 Control passes if security governance activities are consistently performed with proper documentation; fails if activities are inconsistently performed or inadequately documented 7 If failure, the CISO must implement corrective actions within 15 business days and report status to the Executive Committee"
},
{
  "Domain" : "Security",
  "Master" : "SE-2",
  "Topic" : "Identity & Access Management",
  "Control Statement" : "The organisation shall implement and maintains comprehensive identity and access management controls governing authentication, authorisation, and access monitoring across all systems and applications. This includes the complete lifecycle of identity management from screening to provisioning through deprovisioning, ensuring appropriate access levels are maintained and regularly reviewed. The organisation shall implement strong authentication mechanisms and maintains detailed access logs for all critical systems.",
  "ISO42001" : null,
  "ISO27001" : "A.9.1 A.9.2 A.9.3 A.9.4",
  "ISO27701" : "9.2.1 9.2.2 9.2.4",
  "EU AI ACT" : null,
  "NIST RMF" : null,
  "SOC2" : "CC6.1 CC6.2 CC6.3",
  " Key control activities" : "• Weekly, the IAM Administrator reviews access privilege reports using the Access Review Dashboard • Quarterly, the Department Managers review user access rights for their departments using the Access Certification Process • For each new hire, transfer, or termination, the HR Coordinator completes the Identity Lifecycle Form within 1 business day • Monthly, the Security Analyst reviews authentication logs for anomalies using the Authentication Monitoring Tool • Annually, the IAM Manager reviews and tests IAM policies and procedures for effectiveness",
  "Required Evidence" : "• Weekly Access Privilege Review reports (PDF format) • Quarterly Access Certification documentation with manager approvals (PDF format) • Identity Lifecycle Forms for all personnel changes (PDF format) • Monthly Authentication Log Analysis reports (PDF format) • Annual IAM Policy Review documentation with test results (PDF format) • User provisioning and deprovisioning records (System logs) • Multi-factor authentication implementation documentation (PDF format) • Access log retention documentation (PDF format)",
  "Control test plan and procedures" : "1 Select 10 users and verify their access rights are appropriate for their roles 2 Review documentation for 5 recent personnel changes (new hires, transfers, terminations) to verify proper procedures were followed 3 Examine the last three monthly Authentication Log Analysis reports to confirm regular monitoring 4 Select one department and verify the quarterly Access Certification was completed properly 5 Review authentication settings to confirm strong authentication mechanisms are implemented 6 Control passes if IAM controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented 7 If failure, the IAM Manager must implement corrective actions within 10 business days and conduct a comprehensive review of access controls"
},
{
  "Domain" : "Security",
  "Master" : "SE-3",
  "Topic" : "Software Security",
  "Control Statement" : "The organisation shall ensure all software development and deployment activities follow secure development practices throughout the system development lifecycle. This includes implementing secure coding standards, conducting security testing, managing secure configurations, and maintaining robust change management procedures for all production systems. The organisation shall regularly assess applications for security vulnerabilities and maintain secure development environments.",
  "ISO42001" : null,
  "ISO27001" : "A.14.1 A.14.2 A.12.2",
  "ISO27701" : "14.2.1 14.2.2",
  "EU AI ACT" : null,
  "NIST RMF" : null,
  "SOC2" : "CC5.2 CC7.1",
  " Key control activities" : "• Before code commits, developers run the Secure Code Analysis Tool and resolve all critical findings • Weekly, the Security Engineer conducts security testing using the Security Testing Framework • For each release, the Quality Assurance team verifies secure configurations using the Configuration Verification Checklist • Monthly, the Application Security Manager reviews vulnerability assessment results using the Vulnerability Management Dashboard • Quarterly, the Development Manager audits adherence to secure development standards using the SDLC Audit Tool",
  "Required Evidence" : "• Secure Code Analysis Tool reports with resolution documentation (PDF format) • Weekly Security Testing results with findings and remediation (PDF format) • Configuration Verification Checklists for each release (PDF format) • Monthly Vulnerability Assessment reports (PDF format) • Quarterly SDLC Audit reports (PDF format) • Secure coding standards documentation with review history (PDF format) • Security testing procedures and results (PDF format) • Change management records showing security approval for production changes (PDF format)",
  "Control test plan and procedures" : "1 Select three recent code repositories and verify Secure Code Analysis was performed before commit 2 Review the last four weekly Security Testing reports to confirm regular testing occurs 3 For two recent releases, verify Configuration Verification was completed 4 Review the last two monthly Vulnerability Assessment reports to confirm regular monitoring 5 Examine the most recent SDLC Audit report to verify adherence to secure development standards 6 Control passes if secure development practices are consistently followed with proper documentation; fails if practices are inconsistently followed or inadequately documented 7 If failure, the Development Manager must implement corrective actions within 10 business days and conduct additional training for development staff"
},
{
  "Domain" : "Security",
  "Master" : "SE-4",
  "Topic" : "Data Security",
  "Control Statement" : "The organisation shall protect data throughout its lifecycle using appropriate technical and procedural controls, including classification, encryption, and secure handling procedures. This encompasses structured and unstructured data across all storage locations and transmission paths. The organisation shall maintain comprehensive data protection mechanisms, including backup systems, encryption standards, and secure disposal procedures, while ensuring appropriate data classification and handling requirements are enforced.",
  "ISO42001" : null,
  "ISO27001" : "A.8.1-A.8.7 A.10.1 A.10.2 A.12.4 A.12.5 A.14.3",
  "ISO27701" : "8.2.4 8.3.1 8.3.2 8.3.3 10.2.1 10.2.2 11.2.2",
  "EU AI ACT" : null,
  "NIST RMF" : null,
  "SOC2" : "CC6.4-CC6.7 C1.1 C1.2 P5.1-P5.4 P5.6",
  " Key control activities" : "• Monthly, the Data Protection Officer reviews data classification and handling practices using the Data Protection Audit Checklist • Weekly, the Backup Administrator verifies backup integrity using the Backup Verification Process • Quarterly, the Security Engineer tests encryption implementation using the Encryption Testing Framework • For each new data type, the Data Steward completes the Data Classification Form and implements appropriate controls • Annually, the Records Manager reviews and tests data disposal procedures",
  "Required Evidence" : "• Monthly Data Protection Audit reports (PDF format) • Weekly Backup Verification logs (System logs) • Quarterly Encryption Testing results (PDF format) • Data Classification Forms for all data types (PDF format) • Annual Data Disposal Procedure Testing documentation (PDF format) • Data handling training completion records (LMS reports) • Encryption standards documentation with implementation evidence (PDF format) • Data classification inventory (Excel format)",
  "Control test plan and procedures" : "1 Select five data repositories and verify data is classified according to policy 2 Review the last four weekly Backup Verification logs to confirm regular verification 3 For three sensitive data types, verify encryption is implemented according to standards 4 Examine data disposal records for the past quarter to confirm proper procedures are followed 5 Review the most recent Data Protection Audit report to verify compliance with handling requirements 6 Control passes if data protection controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented 7 If failure, the Data Protection Officer must implement corrective actions within 10 business days and conduct a comprehensive review of data protection controls"
},
{
  "Domain" : "Security",
  "Master" : "SE-5",
  "Topic" : "Network Security",
  "Control Statement" : "The organisation shall implement and maintain comprehensive network security controls to protect against unauthorised access, ensure secure communications, and maintain the confidentiality and integrity of data in transit. This includes implementing secure network architectures, maintaining network monitoring capabilities, and ensuring appropriate network segmentation. The organisation shall regularly assess network security controls and maintain comprehensive network logging and monitoring capabilities.",
  "ISO42001" : null,
  "ISO27001" : "A.13.1-A.13.3 A.12.4 A.12.6 A.10.1 A.10.2",
  "ISO27701" : "13.2.1",
  "EU AI ACT" : null,
  "NIST RMF" : null,
  "SOC2" : "CC6.6 CC7.1 CC7.2",
  " Key control activities" : "• Daily, the Network Security Analyst reviews security alerts using the Network Monitoring Dashboard • Weekly, the Network Administrator verifies network configurations using the Configuration Management Tool • Monthly, the Security Engineer conducts network vulnerability scanning using the approved Vulnerability Scanner • Quarterly, the Network Security Manager reviews network segmentation using the Network Architecture Review Process • Annually, the Security Assessment team conducts penetration testing of network security controls",
  "Required Evidence" : "• Daily Network Security Alert Review logs (System logs) • Weekly Network Configuration Verification reports (PDF format) • Monthly Network Vulnerability Scan results with remediation plans (PDF format) • Quarterly Network Architecture Review reports (PDF format) • Annual Penetration Testing reports with findings and remediation (PDF format) • Network security architecture documentation with review history (PDF format) • Network monitoring logs showing continuous monitoring (System logs) • Network segmentation implementation documentation (PDF format)",
  "Control test plan and procedures" : "1 Review network security alert logs from the past 7 days to verify daily review occurred 2 Examine the last four weekly Network Configuration Verification reports 3 For the last two monthly Network Vulnerability Scans, verify findings were remediated according to SLAs 4 Review the most recent Network Architecture Review to confirm proper segmentation 5 Examine the annual Penetration Testing report to verify findings were addressed 6 Control passes if network security controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented 7 If failure, the Network Security Manager must implement corrective actions within 10 business days and conduct additional monitoring"
},
{
  "Domain" : "Security",
  "Master" : "SE-6",
  "Topic" : "Physical Security",
  "Control Statement" : "The organisation shall implement and maintain comprehensive physical security controls to protect information assets, including facilities, equipment, and supporting infrastructure from unauthorised access and environmental threats. This includes maintaining secure physical perimeters, implementing environmental controls, monitoring physical access, and ensuring appropriate protection for equipment and supporting infrastructure.",
  "ISO42001" : null,
  "ISO27001" : "A.11.1 A.11.2 A.11.3 A.11.4 A.11.5",
  "ISO27701" : "11.2.1",
  "EU AI ACT" : null,
  "NIST RMF" : null,
  "SOC2" : "CC6.1",
  " Key control activities" : "• Daily, the Security Operations Center reviews physical access logs using the Physical Access Monitoring System • Weekly, the Facilities Manager inspects physical security controls using the Physical Security Inspection Checklist • Monthly, the Environmental Controls Technician tests environmental systems using the Environmental Control Testing Procedure • Quarterly, the Security Manager reviews physical security incidents using the Incident Analysis Dashboard • Annually, the Physical Security Assessment team conducts a comprehensive assessment of physical security controls",
  "Required Evidence" : "• Daily Physical Access Log Review documentation (System logs) • Weekly Physical Security Inspection reports (PDF format) • Monthly Environmental Control Testing results (PDF format) • Quarterly Physical Security Incident Analysis reports (PDF format) • Annual Physical Security Assessment reports with findings and remediation (PDF format) • Physical access authorization records (PDF format) • Environmental monitoring logs (System logs) • Equipment protection documentation (PDF format)",
  "Control test plan and procedures" : "1 Review physical access logs from the past 7 days to verify daily review occurred 2 Examine the last four weekly Physical Security Inspection reports 3 For two critical facilities, verify environmental controls are tested monthly 4 Review the most recent Quarterly Incident Analysis report to confirm proper incident handling 5 Examine the annual Physical Security Assessment report to verify findings were addressed 6 Control passes if physical security controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented 7 If failure, the Security Manager must implement corrective actions within 15 business days and conduct a comprehensive review of physical security controls"
},
{
  "Domain" : "Safe Responsible AI",
  "Master" : "RS-1",
  "Topic" : "Human Oversight and Intervention",
  "Control Statement" : "The organisation shall implement mechanisms for meaningful human oversight of AI systems, ensuring humans maintain appropriate control over AI decision-making. This includes clearly defined procedures for human monitoring, intervention capabilities, and authority to override AI systems when necessary. Personnel responsible for oversight must receive appropriate training and have sufficient competence and authority to fulfill their responsibilities effectively.",
  "ISO42001" : "A.9.2 A.9.3 A.9.4",
  "ISO27001" : "A.18.1.1 A.18.2.2 A.6.1 A.6.2",
  "ISO27701" : "7.2.2 7.2.5",
  "EU AI ACT" : "14.1-14.5 26.2 4.1",
  "NIST RMF" : "Govern 3.2 Map 3.4 Map 3.5",
  "SOC2" : "CC1.1 CC2.1",
  "Key control activities" : "- Monthly, the AI Oversight Committee reviews system performance reports and intervention logs\n- Quarterly training sessions conducted for oversight personnel on system capabilities and limitations\n- Weekly review of high-risk AI system decisions by domain experts\n- Implementation of human-in-the-loop controls for critical decision points\n- Regular testing of override mechanisms and escalation procedures\n- Documentation of all human interventions and their outcomes",
  "Required Evidence" : "- AI System Oversight Manual with defined roles and procedures (PDF)\n- Training records and competency assessments for oversight personnel (Excel)\n- System performance reports with human review annotations (PDF)\n- Intervention logs documenting override decisions and rationale (Excel)\n- Minutes from AI Oversight Committee meetings (PDF)\n- Technical documentation of human-in-the-loop implementation (PDF)\n- Escalation procedure test results and updates (PDF)",
  "Control test plan and procedures" : "- Review the last 6 months of oversight committee meeting minutes\n- Verify training completion for all oversight personnel\n- Sample 10 high-risk decisions to confirm human review was performed\n- Test override mechanisms on non-production systems to verify functionality\n- Review intervention logs for proper documentation and follow-up\n- Interview 3 oversight personnel to assess understanding of procedures\n- Control passes if all samples show compliance with procedures; fails if any critical steps were missed\n- For failures, Oversight Committee must review and update procedures within 15 days"
},
{
  "Domain" : "Safe Responsible AI",
  "Master" : "RS-2",
  "Topic" : "Safety",
  "Control Statement" : "The organisation shall establish and maintain processes to prevent AI systems from producing outputs that could cause harm to individuals, groups, or society. This includes comprehensive impact assessments, monitoring for potential harms, and implementation of safeguards to prevent prohibited uses or manipulative practices. The organisation must maintain documented evidence of harm prevention measures and regularly assess their effectiveness.",
  "ISO42001" : "A.5.2 A.5.3 A.5.4 A.5.5",
  "ISO27001" : "A.12.1",
  "ISO27701" : "7.2.3 7.2.4",
  "EU AI ACT" : "5.1 5.2 9.1-9.3",
  "NIST RMF" : "Map 1.1 Map 3.1 Map 3.2 Measure 3.1 Measure 3.2",
  "SOC2" : "CC4.1 CC5.1",
  "Key control activities" : "• Before system deployment, the AI Ethics Officer conducts an Impact Assessment using the AI Impact Assessment Framework • Weekly, the AI Safety Engineer monitors system outputs for potential harms using the Safety Monitoring Tool • Monthly, the Product Manager reviews user feedback for harm indicators using the Feedback Analysis Tool • Quarterly, the AI Governance Committee reviews harm prevention measures using the Harm Prevention Effectiveness Report • For high-risk AI systems, the Safety Supervisor conducts daily safety reviews using the Safety Review Checklist",
  "Required Evidence" : "• AI Impact Assessment reports with mitigation measures (PDF format) • Weekly Safety Monitoring reports with findings and actions (PDF format) • Monthly User Feedback Analysis reports highlighting harm indicators (PDF format) • Quarterly Harm Prevention Effectiveness reports with recommendations (PDF format) • Daily Safety Review Checklists for high-risk systems (PDF format) • Prohibited use cases documentation with preventive controls (Word documents) • Safeguards implementation documentation (PDF format) • Harm prevention training completion records (LMS reports)",
  "Control test plan and procedures" : "1 Select two AI systems and verify Impact Assessments were conducted before deployment 2 Review Safety Monitoring reports from the past 4 weeks to verify weekly monitoring occurred 3 For one high-risk AI system, verify daily Safety Reviews are conducted and documented 4 Review the most recent Quarterly Harm Prevention Effectiveness report to confirm evaluation of measures 5 Verify safeguards against prohibited uses are implemented and functioning 6 Control passes if harm prevention controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented 7 If failure, the AI Safety Engineer must implement corrective actions within 5 business days and conduct additional monitoring"
},
{
  "Domain" : "Safe Responsible AI",
  "Master" : "RS-3",
  "Topic" : "Robustness",
  "Control Statement" : "The organisation shall ensure AI systems demonstrate consistent and reliable performance across their intended operating conditions, including edge cases and unexpected scenarios. Systems must be resilient against errors, adversarial attacks, and data quality issues. Regular testing and monitoring shall be conducted to verify robustness, with particular attention to system behavior under stress conditions or when encountering novel situations.",
  "ISO42001" : "A.9.4",
  "ISO27001" : "A.17.1 A.17.2",
  "ISO27701" : "7.2.8",
  "EU AI ACT" : "8.1 8.2 15.1 15.4 15.5",
  "NIST RMF" : "Map 2.1 Map 2.2 Measure 4.2 Measure 4.3",
  "SOC2" : "CC7.1 CC8.1",
  "Key control activities" : "• Weekly, the AI Quality Engineer conducts reliability testing using the Reliability Testing Framework • Monthly, the Security Engineer performs adversarial testing using the Adversarial Testing Toolkit • Quarterly, the AI Performance Analyst conducts stress testing using the Stress Testing Procedure • For each system update, the Test Engineer verifies edge case handling using the Edge Case Test Suite • Annually, the Resilience Team conducts comprehensive resilience assessment using the Resilience Assessment Framework",
  "Required Evidence" : "• Weekly Reliability Testing reports with results and issues (PDF format) • Monthly Adversarial Testing reports with findings and mitigations (PDF format) • Quarterly Stress Testing reports demonstrating system behavior under load (PDF format) • Edge Case Test results for each system update (PDF format) • Annual Resilience Assessment reports with recommendations (PDF format) • Error handling documentation with test results (PDF format) • Robustness specifications with verification evidence (PDF format) • System reliability metrics with trend analysis (Excel format)",
  "Control test plan and procedures" : "1 Review Reliability Testing reports from the past 4 weeks to verify weekly testing occurred 2 Examine the last two monthly Adversarial Testing reports to confirm security testing 3 For one system that underwent updates in the past quarter, verify Edge Case Testing was performed 4 Review the most recent Quarterly Stress Testing report to confirm system behavior under load 5 Verify error handling mechanisms are implemented and tested 6 Control passes if robustness and reliability controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented 7 If failure, the AI Quality Engineer must implement corrective actions within 10 business days and conduct additional testing"
},
{
  "Domain" : "Safe Responsible AI",
  "Master" : "RS-4",
  "Topic" : "Explainability and Interpretability",
  "Control Statement" : "The organisation shall ensure AI systems' decisions and outputs can be appropriately explained and interpreted by relevant stakeholders. This includes maintaining comprehensive documentation of system behaviour, providing clear explanations of AI-driven decisions when required, and ensuring transparency about system capabilities and limitations. Methods for generating explanations must be appropriate to the context and audience.",
  "ISO42001" : "A.5.3",
  "ISO27001" : null,
  "ISO27701" : "7.2.1",
  "EU AI ACT" : "50.2 50.3 50.4 50.5",
  "NIST RMF" : "Govern 4.2 Map 2.2 Map 2.3 Measure 2.8",
  "SOC2" : "CC2.2 CC2.3",
  "Key control activities" : "• For each AI model, the AI Explainability Specialist documents explanation methods using the Explainability Documentation Template • Monthly, the AI Product Manager reviews explanation quality using the Explanation Quality Assessment Tool • Quarterly, the UX Researcher conducts user testing of explanations using the Explanation Usability Testing Protocol • For high-risk decisions, the Decision Supervisor verifies explanation adequacy using the High-Risk Decision Review Checklist • Annually, the AI Governance Committee reviews explainability practices using the Explainability Effectiveness Review",
  "Required Evidence" : "• Explainability Documentation for each AI model (PDF format) • Monthly Explanation Quality Assessment reports (PDF format) • Quarterly Explanation Usability Testing reports with findings (PDF format) • High-Risk Decision Review Checklists with verification (PDF format) • Annual Explainability Effectiveness Review reports with recommendations (PDF format) • System behavior documentation with explanation capabilities (Word documents) • Explanation method technical documentation (PDF format) • Training materials for staff on interpreting and communicating explanations (PDF format)",
  "Control test plan and procedures" : "1 Select three AI models and verify Explainability Documentation exists and is complete 2 Review the last three monthly Explanation Quality Assessment reports 3 For five high-risk decisions made in the past quarter, verify explanation adequacy was reviewed 4 Examine the most recent Quarterly Explanation Usability Testing report to confirm user understanding 5 Test explanation generation for a sample decision to verify functionality 6 Control passes if explainability controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented 7 If failure, the AI Explainability Specialist must implement corrective actions within 15 business days and conduct additional documentation"
},
{
  "Domain" : "Safe Responsible AI",
  "Master" : "RS-5",
  "Topic" : "Fairness and Bias Management",
  "Control Statement" : "The organisation shall implement processes to identify, assess, and mitigate unfair bias in AI systems throughout their lifecycle. This includes ensuring training data is representative and appropriate, regularly testing for disparate impact across protected characteristics, and maintaining documented evidence of fairness assessments and mitigation measures. The organisation must regularly validate that AI systems maintain fairness standards in operation.",
  "ISO42001" : "A.5.4",
  "ISO27001" : null,
  "ISO27701" : "7.2.6",
  "EU AI ACT" : "5.1 26.4",
  "NIST RMF" : "Measure 2.11 Govern 5.2 Measure 2.2",
  "SOC2" : "CC1.3 CC5.3",
  "Key control activities" : "• Before model training, the Data Scientist completes the Dataset Bias Assessment using the Bias Detection Framework • Monthly, the AI Ethics Officer reviews model outputs for disparate impact using the Fairness Monitoring Tool • Quarterly, the Data Science team conducts comprehensive fairness testing using the Fairness Testing Protocol • For each major model update, the AI Validation Specialist verifies fairness metrics using the Fairness Validation Checklist • Annually, the AI Governance Committee reviews fairness practices using the Fairness Effectiveness Review",
  "Required Evidence" : "Dataset Bias Assessment reports with mitigation strategies (PDF format) Monthly Disparate Impact Monitoring reports (PDF format) Quarterly Fairness Testing reports with results across protected characteristics (PDF format) Fairness Validation Checklists for model updates (PDF format) Annual Fairness Effectiveness Review reports with recommendations (PDF format) Data representativeness analysis documentation (Excel format) Fairness metrics tracking documentation with trend analysis (Excel format) Bias mitigation technique implementation documentation (PDF format) Protected characteristic testing results for all models (PDF format)",
  "Control test plan and procedures" : "• Select two AI models and verify Dataset Bias Assessments were conducted before training • Review the last three monthly Disparate Impact Monitoring reports to confirm regular monitoring • For one model that underwent updates in the past quarter, verify Fairness Validation was performed • Examine the most recent Quarterly Fairness Testing report to confirm comprehensive evaluation • Test one model with a sample dataset to verify fairness metrics are calculated correctly • Control passes if fairness controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the AI Ethics Officer must implement corrective actions within 10 business days and conduct additional fairness testing"
},
{
  "Domain" : "Privacy",
  "Master" : "PR-1",
  "Topic" : "Privacy by Design and Governance",
  "Control Statement" : "The organisation shall implement privacy by design principles in all AI systems, ensuring privacy considerations are embedded from initial planning through system retirement. This includes establishing and maintaining comprehensive privacy policies, conducting privacy impact assessments, defining clear privacy roles and responsibilities, and integrating privacy requirements into project management processes. The organisation shall establish privacy governance structures, maintain documentation of privacy decisions, regularly review privacy controls for effectiveness, and ensure special categories of personal data are processed only when strictly necessary and with appropriate safeguards. Senior management shall demonstrate commitment to privacy through resource allocation and oversight of privacy initiatives.",
  "ISO42001" : null,
  "ISO27001" : null,
  "ISO27701" : "6.1.1 6.1.2 6.2.1-6.2.4 7.2.1-7.2.3 7.2.5 7.2.7 12.2.1 A.7.4.1-A.7.4.9 B.8.4",
  "EU AI ACT" : "10.5 26.9 27.4",
  "NIST RMF" : null,
  "SOC2" : "P1.1 P1.2 P1.3",
  "Key control activities" : "• Before project initiation, the Privacy Officer conducts a Privacy Impact Assessment using the approved PIA template • Quarterly, the Privacy Governance Committee reviews privacy initiatives using the Privacy Program Dashboard • For each system design, the Privacy Engineer verifies privacy requirements using the Privacy Requirements Checklist • Monthly, the Data Protection Officer reviews privacy controls using the Privacy Control Assessment Tool • Annually, the Privacy Audit team conducts a comprehensive privacy audit using the Privacy Audit Framework",
  "Required Evidence" : "• Privacy Impact Assessment reports with mitigation strategies (PDF format) • Quarterly Privacy Governance Committee meeting minutes (PDF format) • Privacy Requirements Checklists for all system designs (PDF format) • Monthly Privacy Control Assessment reports (PDF format) • Annual Privacy Audit reports with findings and remediation plans (PDF format) • Privacy policy documentation with review history (Word documents) • Privacy role assignment documentation (PDF format) • Privacy requirements in project management documentation (PDF format)",
  "Control test plan and procedures" : "• Select three AI projects initiated in the past year and verify Privacy Impact Assessments were conducted • Review the last two quarterly Privacy Governance Committee meeting minutes • For two systems designed in the past six months, verify Privacy Requirements Checklists were completed • Examine the last three monthly Privacy Control Assessment reports to confirm regular reviews • Review the most recent Annual Privacy Audit report to verify comprehensive evaluation • Control passes if privacy by design controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Privacy Officer must implement corrective actions within 15 business days and conduct a comprehensive review of privacy controls"
},
{
  "Domain" : "Privacy",
  "Master" : "PR-2",
  "Topic" : "Personal Data Management",
  "Control Statement" : "The organisation shall implement operational processes for the responsible collection, use, storage, and disposal of personal data in AI systems. This includes maintaining data inventories, implementing data classification schemes, managing data retention schedules, and ensuring appropriate data handling throughout the information lifecycle. The organisation shall obtain and maintain records of consent for data processing, provide individuals with access to their data, implement processes for handling data subject requests, and ensure data quality standards are maintained. Clear procedures for data minimisation, purpose limitation, and secure disposal shall be established and followed.",
  "ISO42001" : null,
  "ISO27001" : null,
  "ISO27701" : "8.2.1-8.2.4 8.3.1-8.3.3 A.7.2.1-A.7.2.8 A.7.3.1-A.7.3.10 7.4.5 A.7.5.1-A.7.5.4 B.8.2 B.8.3 B.8.4.2 B.8.5",
  "EU AI ACT" : null,
  "NIST RMF" : null,
  "SOC2" : "P2.1 P2.2 P3.1-P3.3 P4.1-P4.3",
  "Key control activities" : "• Weekly, the Privacy Coordinator reviews data subject requests using the Request Management System • Monthly, the Data Inventory Manager updates the data inventory using the Data Mapping Tool • Quarterly, the Privacy Officer reviews consent management processes using the Consent Management Audit • For each new data collection, the Data Protection Officer verifies consent mechanisms using the Consent Verification Checklist • Annually, the Data Quality team verifies data accuracy and completeness using the Data Quality Assessment Framework",
  "Required Evidence" : "• Weekly Data Subject Request logs with resolution documentation (System logs) • Monthly Data Inventory updates with change documentation (Excel format) • Quarterly Consent Management Audit reports (PDF format) • Consent Verification Checklists for new data collections (PDF format) • Annual Data Quality Assessment reports (PDF format) • Data subject request response templates (Word documents) • Data retention schedule implementation evidence (Excel format) • Data minimization assessment documentation (PDF format)",
  "Control test plan and procedures" : "• Select 10 data subject requests from the past quarter and verify they were handled according to policy • Review the last three monthly Data Inventory updates to confirm regular maintenance • For three new data collections in the past six months, verify Consent Verification Checklists were completed • Examine the most recent Quarterly Consent Management Audit to confirm process evaluation • Test the data subject request process by submitting a test request and tracking response • Control passes if data subject rights controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Privacy Coordinator must implement corrective actions within 10 business days and conduct additional training"
},
{
  "Domain" : "Privacy",
  "Master" : "PR-3",
  "Topic" : "Privacy Compliance and Monitoring",
  "Control Statement" : "The organisation shall establish processes to monitor compliance with privacy requirements, detect and respond to privacy incidents, and ensure continuous improvement of privacy controls. This includes conducting regular privacy audits, monitoring data processing activities, managing privacy incidents, ensuring supplier compliance with privacy requirements, and maintaining business continuity plans that address privacy considerations. The organisation shall implement privacy metrics, conduct regular assessments, comply with breach notification requirements, and demonstrate ongoing compliance with applicable privacy regulations through documented evidence.",
  "ISO42001" : null,
  "ISO27001" : null,
  "ISO27701" : "12.2.2 15.2.1 16.2.1 16.2.2 17.2.1 18.2.1 18.2.2 A.7.2.5-A.7.2.7 A.7.3.6 B.8.2.4 B.8.2.5",
  "EU AI ACT" : null,
  "NIST RMF" : null,
  "SOC2" : "P6.1 P6.2 P6.3 P6.4 P6.5",
  "Key control activities" : "• Monthly, the Privacy Program Manager reviews compliance metrics using the Privacy Compliance Dashboard • Quarterly, the Privacy Incident Response team conducts tabletop exercises using the Incident Response Playbook • Monthly, the Supplier Manager reviews privacy compliance of third parties using the Supplier Privacy Assessment Tool • Quarterly, the Business Continuity Manager verifies privacy considerations in continuity plans using the Privacy Continuity Checklist • Annually, the Privacy Metrics team conducts a comprehensive metrics review using the Privacy Metrics Framework",
  "Required Evidence" : "• Monthly Privacy Compliance Dashboard reports (PDF format) • Quarterly Privacy Incident Response Exercise reports (PDF format) • Monthly Supplier Privacy Assessment reports (PDF format) • Quarterly Privacy Continuity Checklist verification (PDF format) • Annual Privacy Metrics Review reports (PDF format) • Privacy incident logs with resolution documentation (Excel format) • Privacy audit findings and remediation tracking (Excel format) • Business continuity test results with privacy considerations (PDF format)",
  "Control test plan and procedures" : "• Review the last three monthly Privacy Compliance Dashboard reports to confirm regular monitoring • Examine the most recent Quarterly Privacy Incident Response Exercise report to verify testing • Select five key suppliers and verify monthly Privacy Assessments were conducted • Review the last two quarterly Privacy Continuity Checklist verifications • Examine the Annual Privacy Metrics Review report to confirm comprehensive evaluation • Control passes if privacy program management controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Privacy Program Manager must implement corrective actions within 15 business days and conduct a comprehensive review of the privacy program"
},
{
  "Domain" : "Privacy",
  "Master" : "PR-4",
  "Topic" : "Privacy-Enhancing Technologies and Mechanisms",
  "Control Statement" : "The organisation shall implement appropriate technical mechanisms and privacy-enhancing technologies in AI systems to protect personal data and ensure privacy by default. This includes implementing encryption for data at rest and in transit, role-based access control mechanisms, data minimisation techniques, anonymisation and pseudonymisation methods, and secure deletion capabilities. The organisation shall ensure these mechanisms are appropriate for the sensitivity of the data, regularly tested for effectiveness, and updated as privacy-enhancing technologies evolve. This includes how technical controls are documented, validated, and integrated into the system architecture to provide defense in depth for privacy protection.",
  "ISO42001" : null,
  "ISO27001" : null,
  "ISO27701" : "9.2.1-9.2.4 10.2.1-10.2.2 11.2.1-11.2.2 13.2.1 14.2.1-14.2.2 A.7.4.5 A.7.4.9 B.8.4.3",
  "EU AI ACT" : null,
  "NIST RMF" : null,
  "SOC2" : "P5.1 P5.2 P5.3 P5.4 P5.5 P5.6",
  "Key control activities" : "• Quarterly, the Privacy Engineer reviews privacy technology implementation using the Privacy Technology Assessment Tool • Monthly, the Security Engineer verifies encryption implementation using the Encryption Verification Checklist • For each system with personal data, the Access Control Manager reviews access controls using the Access Review Process • Quarterly, the Data Protection team tests anonymization techniques using the Anonymization Testing Protocol • Annually, the Privacy Technology team evaluates new privacy technologies using the Technology Evaluation Framework",
  "Required Evidence" : "• Quarterly Privacy Technology Assessment reports (PDF format) • Monthly Encryption Verification reports (PDF format) • Access Control Review documentation for systems with personal data (PDF format) • Quarterly Anonymization Testing reports (PDF format) • Annual Privacy Technology Evaluation reports (PDF format) • Encryption standards implementation documentation (PDF format) • Role-based access control matrix (Excel format) • Data minimization technique implementation evidence (PDF format)",
  "Control test plan and procedures" : "• Select three systems with personal data and verify appropriate privacy technologies are implemented • Review the last three monthly Encryption Verification reports to confirm regular verification • For two systems, verify Access Control Reviews were conducted in the past quarter • Examine the most recent Quarterly Anonymization Testing report to confirm effectiveness testing • Test one system's privacy controls by attempting unauthorized access and verifying prevention • Control passes if privacy-enhancing technologies are consistently implemented with proper documentation; fails if technologies are inconsistently implemented or inadequately documented • If failure, the Privacy Engineer must implement corrective actions within 10 business days and conduct additional testing"
},
{
  "Domain" : "Assurance and Audit",
  "Master" : "AA-1",
  "Topic" : "Internal Assessment & Audit",
  "Control Statement" : "The organisation shall establish and maintain comprehensive internal assessment and audit procedures for AI systems throughout their lifecycle. This includes documented verification of controls and validation of system behavior in both controlled and real-world conditions. Internal audits must evaluate compliance with organisational policies and procedures. Internal assessment and audit activities must cover normal operations, edge cases, and stress conditions. The organisation shall maintain evidence of all audit activities, findings, and remediation efforts.",
  "ISO42001" : "9.1 9.2 9.3 A.6.2.4",
  "ISO27001" : "9.1 9.2 9.3 A.18.2",
  "ISO27701" : "8.2.3 18.2.2 A.7.2.5 A.7.4.3",
  "EU AI ACT" : "9.7-9.8 17.1-17.2 60.1-60.9 61.1 61.2",
  "NIST RMF" : "Map 2.3 Measure 2.1 Measure 2.3 Measure 2.5",
  "SOC2" : "PI1.1 PI1.2 CC4.1",
  "Key control activities" : "• Monthly, the Internal Audit Manager conducts controls testing using the Internal Control Testing Framework • Quarterly, the Compliance team performs compliance verification using the Compliance Verification Checklist • For each new or significantly changed system, the Validation team conducts validation testing using the Validation Protocol • Semi-annually, the AI Governance Committee reviews audit findings using the Audit Findings Dashboard • Annually, external assessors conduct independent assessments using the External Assessment Framework",
  "Required Evidence" : "• Monthly Internal Control Testing reports with findings (PDF format) • Quarterly Compliance Verification reports (PDF format) • Validation Testing reports for new or changed systems (PDF format) • Semi-annual Audit Findings Review documentation (PDF format) • Annual External Assessment reports with findings (PDF format) • Audit methodology documentation (Word documents) • Remediation tracking logs with status updates (Excel format) • Evidence of auditor independence and competence (PDF format)",
  "Control test plan and procedures" : "• Review the last three monthly Internal Control Testing reports to confirm regular testing • Examine the most recent Quarterly Compliance Verification report • For two new or changed systems from the past six months, verify Validation Testing was conducted • Review the last Semi-annual Audit Findings Review documentation to confirm findings analysis • Examine the most recent Annual External Assessment report and verify findings were addressed • Control passes if assessment and audit controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Internal Audit Manager must implement corrective actions within 15 business days and conduct additional testing"
},
{
  "Domain" : "Assurance and Audit",
  "Master" : "AA-2",
  "Topic" : "Independent Assessment and Certification",
  "Control Statement" : "The organisation shall ensure regular independent assessments of AI systems are conducted and maintain necessary certifications. Independent assessors must have appropriate expertise and authority to evaluate compliance with regulatory requirements and performance standards. The organisation shall obtain and maintain required certifications, track certification status, and implement corrective actions when gaps are identified. Assessment and certification activities must be documented, including findings and evidence of remediation.",
  "ISO42001" : "9.1 9.3 10.1 10.2",
  "ISO27001" : "9.1 9.3 10.1 10.2 A.18.1 A.18.2",
  "ISO27701" : "7.2.1",
  "EU AI ACT" : "20.1 22.3-22.4 40.1 43.1-43.4 44.2 44.3",
  "NIST RMF" : "Measure 1.3 Measure 4.2 Govern 4.3",
  "SOC2" : "CC4.2 CC3.1",
  "Key control activities" : "• Monthly, the Internal Audit Manager conducts controls testing using the Internal Control Testing Framework • Quarterly, the Compliance team performs compliance verification using the Compliance Verification Checklist • For each new or significantly changed system, the Validation team conducts validation testing using the Validation Protocol • Semi-annually, the AI Governance Committee reviews audit findings using the Audit Findings Dashboard • Annually, external assessors conduct independent assessments using the External Assessment Framework",
  "Required Evidence" : "• Monthly Internal Control Testing reports with findings (PDF format) • Quarterly Compliance Verification reports (PDF format) • Validation Testing reports for new or changed systems (PDF format) • Semi-annual Audit Findings Review documentation (PDF format) • Annual External Assessment reports with findings (PDF format) • Audit methodology documentation (Word documents) • Remediation tracking logs with status updates (Excel format) • Evidence of auditor independence and competence (PDF format)",
  "Control test plan and procedures" : "• Review the last three monthly Internal Control Testing reports to confirm regular testing • Examine the most recent Quarterly Compliance Verification report • For two new or changed systems from the past six months, verify Validation Testing was conducted • Review the last Semi-annual Audit Findings Review documentation to confirm findings analysis • Examine the most recent Annual External Assessment report and verify findings were addressed • Control passes if assessment and audit controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Internal Audit Manager must implement corrective actions within 15 business days and conduct additional testing"
},
{
  "Domain" : "Assurance and Audit",
  "Master" : "AA-3",
  "Topic" : "Safety and Security Validation",
  "Control Statement" : "The organisation shall conduct regular testing of AI system safety and security controls, including assessment of cybersecurity measures, resilience against attacks, and ability to fail safely. Testing must verify that systems operate within defined risk tolerances and maintain effectiveness of protective controls. Validation must include both automated testing and expert review of safety measures. The organisation shall maintain documentation of all safety and security assessments, including methodology, results, and remediation of identified issues.",
  "ISO42001" : "9.1 9.3",
  "ISO27001" : "9.1 9.3 A.18.1 A.18.2",
  "ISO27701" : "7.2.5",
  "EU AI ACT" : "41.1-41.2 42.1-42.2",
  "NIST RMF" : "Measure 2.6 Measure 2.7",
  "SOC2" : "CC7.1",
  "Key control activities" : "• Monthly, the Security Testing team conducts penetration testing using the Security Testing Framework • Quarterly, the Cybersecurity team performs threat modeling using the Threat Modeling Methodology • For each major release, the Safety Engineer conducts safety testing using the Safety Testing Protocol • Monthly, the Security Operations team reviews attack simulation results using the Attack Simulation Tool • Annually, the Safety and Security Assessment team conducts comprehensive assessments using the Assessment Framework",
  "Required Evidence" : "• Monthly Penetration Testing reports with findings (PDF format) • Quarterly Threat Modeling reports (PDF format) • Safety Testing reports for major releases (PDF format) • Monthly Attack Simulation reports (PDF format) • Annual Safety and Security Assessment reports (PDF format) • Security testing methodology documentation (Word documents) • Remediation tracking for identified vulnerabilities (Excel format) • Evidence of tester independence and competence (PDF format)",
  "Control test plan and procedures" : "• Review the last three monthly Penetration Testing reports to confirm regular testing • Examine the most recent Quarterly Threat Modeling report to verify threat analysis • For two major releases from the past six months, verify Safety Testing was conducted • Review the last three monthly Attack Simulation reports to confirm regular testing • Examine the Annual Safety and Security Assessment report and verify findings were addressed • Control passes if safety and security testing controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Security Testing Manager must implement corrective actions within 10 business days and conduct additional testing"
},
{
  "Domain" : "Operational Monitoring",
  "Master" : "OM-1",
  "Topic" : "System Performance Monitoring",
  "Control Statement" : "The organisation shall implement continuous monitoring of AI system performance and behavior in production environments. This includes automated monitoring of key performance indicators, tracking of system outputs, detection of anomalies or degradation in performance, and validation that systems operate within defined parameters. The organisation must maintain documentation of monitoring results, performance trends, and actions taken to address identified issues. Monitoring activities shall be proportional to the system's risk level and complexity.",
  "ISO42001" : "8.1-8.3 A.6.2.6",
  "ISO27001" : "8.1-8.3 A.12.3 A.12.6 A.17.1 A.17.2",
  "ISO27701" : "12.2.2 A.7.4.3",
  "EU AI ACT" : "26.5 72.1 72.2 72.3 72.4",
  "NIST RMF" : "Measure 1.2 Measure 2.4 Manage 2.2 Manage 2.4",
  "SOC2" : "CC4.1 CC4.2 A1.1 A1.2",
  "Key control activities" : "• Daily, the Operations team reviews system alerts using the Monitoring Dashboard • Weekly, the Performance Analyst reviews performance metrics using the Performance Monitoring Tool • For high-risk AI systems, the Monitoring Specialist conducts daily in-depth reviews using the Critical System Monitoring Checklist • Monthly, the AI Operations Manager reviews monitoring effectiveness using the Monitoring Effectiveness Report • Quarterly, the Monitoring Governance Committee reviews monitoring strategy using the Monitoring Strategy Review Framework",
  "Required Evidence" : "• Daily System Alert Review logs (System logs) • Weekly Performance Metrics Review reports (PDF format) • Daily Critical System Monitoring Checklists for high-risk systems (PDF format) • Monthly Monitoring Effectiveness reports (PDF format) • Quarterly Monitoring Strategy Review reports (PDF format) • Monitoring configuration documentation (Word documents) • Alert threshold documentation with justification (Excel format) • Monitoring coverage maps showing system coverage (PDF format)",
  "Control test plan and procedures" : "• Review system alert logs from the past 7 days to verify daily review occurred • Examine the last four weekly Performance Metrics Review reports to confirm regular analysis • For two high-risk AI systems, verify daily Critical System Monitoring was conducted for the past week • Review the most recent Monthly Monitoring Effectiveness report to confirm evaluation of monitoring • Test the monitoring system by triggering a test alert and verifying proper detection and response • Control passes if monitoring and logging controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the AI Operations Manager must implement corrective actions within 5 business days and conduct additional monitoring"
},
{
  "Domain" : "Operational Monitoring",
  "Master" : "OM-2",
  "Topic" : "Event Logging",
  "Control Statement" : "The organisation shall maintain comprehensive logs of AI system events and operations throughout their lifecycle. Logging systems must capture relevant operational data including system usage, input data references, and verification of results. Logs must be retained for required retention periods, protected from unauthorised access or modification, and made available to authorities when required. The organisation shall ensure logging systems enable effective compliance verification and support incident investigations.",
  "ISO42001" : "A.6.2.8",
  "ISO27001" : "A.12.6 A.12.7",
  "ISO27701" : "12.2.2",
  "EU AI ACT" : "12.1-12.3 19.1-19.2 21.2 26.6",
  "NIST RMF" : "Govern 4.3",
  "SOC2" : "CC7.2 CC7.3",
  "Key control activities" : "• Daily, the Operations team reviews system alerts using the Monitoring Dashboard • Weekly, the Performance Analyst reviews performance metrics using the Performance Monitoring Tool • For high-risk AI systems, the Monitoring Specialist conducts daily in-depth reviews using the Critical System Monitoring Checklist • Monthly, the AI Operations Manager reviews monitoring effectiveness using the Monitoring Effectiveness Report • Quarterly, the Monitoring Governance Committee reviews monitoring strategy using the Monitoring Strategy Review Framework",
  "Required Evidence" : "• Daily System Alert Review logs (System logs) • Weekly Performance Metrics Review reports (PDF format) • Daily Critical System Monitoring Checklists for high-risk systems (PDF format) • Monthly Monitoring Effectiveness reports (PDF format) • Quarterly Monitoring Strategy Review reports (PDF format) • Monitoring configuration documentation (Word documents) • Alert threshold documentation with justification (Excel format) • Monitoring coverage maps showing system coverage (PDF format)",
  "Control test plan and procedures" : "• Review system alert logs from the past 7 days to verify daily review occurred • Examine the last four weekly Performance Metrics Review reports to confirm regular analysis • For two high-risk AI systems, verify daily Critical System Monitoring was conducted for the past week • Review the most recent Monthly Monitoring Effectiveness report to confirm evaluation of monitoring • Test the monitoring system by triggering a test alert and verifying proper detection and response • Control passes if monitoring and logging controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the AI Operations Manager must implement corrective actions within 5 business days and conduct additional monitoring"
},
{
  "Domain" : "Operational Monitoring",
  "Master" : "OM-3",
  "Topic" : "Continuous Improvement",
  "Control Statement" : "The organisation shall establish and maintain a systematic approach to continuous improvement of AI systems throughout their operational lifecycle. This includes implementing processes to gather and analyse performance data, user feedback, and operational metrics to identify opportunities for enhancement. The organisation shall maintain documented improvement plans that outline specific objectives, timelines, and success criteria. Regular reviews must be conducted to evaluate the effectiveness of improvements and identify new areas for optimisation. The organisation shall ensure that improvement initiatives are prioritised based on operational impact and risk considerations, with clear processes for implementing and validating changes.",
  "ISO42001" : "9.1 10.1 10.2 A.10.4",
  "ISO27001" : "9.1 10.1 10.2 A.18.2 A.15.2 A.12.6 A.18.1",
  "ISO27701" : "A.7.4.3 A.7.3.6",
  "EU AI ACT" : "17.1 72.1 72.2 72.3 72.4",
  "NIST RMF" : "Manage 4.1 Manage 4.2",
  "SOC2" : "CC3.3 A1.3",
  "Key control activities" : "• Monthly, the Process Improvement Manager reviews improvement initiatives using the Improvement Tracking Tool • Quarterly, the AI Quality team analyzes performance metrics using the Performance Analysis Framework • After each incident, the Incident Review team conducts post-incident reviews using the Incident Learning Process • Semi-annually, the User Experience team collects and analyzes user feedback using the Feedback Analysis Tool • Annually, the AI Governance Committee reviews improvement priorities using the Improvement Prioritization Framework",
  "Required Evidence" : "• Monthly Improvement Initiative Tracking reports (PDF format) • Quarterly Performance Analysis reports with improvement recommendations (PDF format) • Post-Incident Review reports with lessons learned (PDF format) • Semi-annual User Feedback Analysis reports (PDF format) • Annual Improvement Prioritization reports (PDF format) • Improvement implementation plans with timelines (Word documents) • Improvement effectiveness metrics (Excel format) • Documentation of implemented improvements (Various formats)",
  "Control test plan and procedures" : "• Review the last three monthly Improvement Initiative Tracking reports to confirm regular monitoring • Examine the most recent Quarterly Performance Analysis report to verify metrics analysis • For three incidents from the past quarter, verify Post-Incident Reviews were conducted • Review the most recent Semi-annual User Feedback Analysis report to confirm feedback collection • Select three improvement initiatives implemented in the past year and verify effectiveness was measured • Control passes if continuous improvement controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Process Improvement Manager must implement corrective actions within 15 business days and conduct a comprehensive review of improvement processes"
},
{
  "Domain" : "Third Party & Supply Chain",
  "Master" : "TP-1",
  "Topic" : "Third-Party Provider Responsibilities",
  "Control Statement" : "The organisation shall establish clear accountability for AI systems when working with third parties, distributors, importers, or suppliers. This includes documenting responsibilities when AI systems are modified or repurposed, ensuring proper handover of obligations between parties, and maintaining evidence of agreed responsibilities. The organisation must obtain necessary information and technical access from third-party suppliers to ensure regulatory compliance, while respecting confidentiality and intellectual property rights.",
  "ISO42001" : "A.10.2",
  "ISO27001" : "A.15.1",
  "ISO27701" : "15.2.1 A.7.2.6-A.7.2.7 B.8.5.6-B.8.5.8",
  "EU AI ACT" : "25.1 25.2 25.3 25.4",
  "NIST RMF" : "Map 4.1 Govern 6.1",
  "SOC2" : "CC2.3",
  "Key control activities" : "• Before engagement, the Vendor Manager conducts vendor assessment using the Third-Party Risk Assessment Tool • Quarterly, the Compliance team reviews third-party compliance using the Compliance Verification Checklist • Monthly, the Contract Manager reviews contract obligations using the Contract Compliance Dashboard • For critical third parties, the Relationship Manager conducts monthly performance reviews using the Performance Review Template • Annually, the Third-Party Governance Committee reviews third-party management strategy using the Strategy Review Framework",
  "Required Evidence" : "• Third-Party Risk Assessment reports for all vendors (PDF format) • Quarterly Third-Party Compliance Verification reports (PDF format) • Monthly Contract Compliance Dashboard reports (PDF format) • Monthly Performance Review reports for critical third parties (PDF format) • Annual Third-Party Management Strategy Review reports (PDF format) • Responsibility matrix documenting handover of obligations (Excel format) • Technical access documentation for third-party systems (PDF format) • Evidence of contractual requirements for regulatory compliance (PDF format)",
  "Control test plan and procedures" : "• Select five third-party vendors and verify Risk Assessments were conducted before engagement • Review the last two quarterly Third-Party Compliance Verification reports • For three critical third parties, verify monthly Performance Reviews were conducted for the past quarter • Examine documentation to confirm clear delineation of responsibilities between parties • For one third-party AI system, verify technical access provisions are implemented • Control passes if third-party accountability controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Vendor Manager must implement corrective actions within 15 business days and conduct additional assessments"
},
{
  "Domain" : "Third Party & Supply Chain",
  "Master" : "TP-2",
  "Topic" : "Supplier Risk Management",
  "Control Statement" : "The organisation shall implement comprehensive processes to identify, assess, manage, and monitor risks associated with third-party AI suppliers and service providers throughout the engagement lifecycle. This includes evaluating supplier capabilities during selection, establishing security and privacy requirements in supplier agreements, maintaining contingency plans for critical third-party dependencies, and implementing continuous monitoring of supplier performance and compliance. The organisation shall regularly assess supplier adherence to established requirements, including security standards, privacy requirements, and service level agreements. Performance monitoring must include collection and evaluation of feedback, documentation of monitoring results, and implementation of appropriate actions when issues are identified. Regular reviews of supplier risk assessments and performance metrics shall inform decisions about continuing or modifying supplier relationships.",
  "ISO42001" : "A.10.3",
  "ISO27001" : "A.15.1 A.15.2",
  "ISO27701" : "15.2.1 A.7.2.6 A.7.5.1-A.7.5.2 B.8.5.1-B.8.5.2",
  "EU AI ACT" : 25.4,
  "NIST RMF" : "Govern 5.1 Manage 3.1 Govern 6.1 Govern 6.2",
  "SOC2" : "CC9.2",
  "Key control activities" : "• Quarterly, the Third-Party Risk Manager updates risk assessments using the Third-Party Risk Management Tool • Monthly, the Supplier Manager reviews security compliance using the Security Compliance Verification Checklist • For critical suppliers, the Continuity Manager verifies contingency plans using the Contingency Testing Protocol • Quarterly, the Performance Analyst reviews supplier performance using the Supplier Performance Dashboard • Annually, the Third-Party Governance Committee reviews risk management effectiveness using the Effectiveness Review Framework",
  "Required Evidence" : "• Quarterly Third-Party Risk Assessment updates (PDF format) • Monthly Security Compliance Verification reports (PDF format) • Contingency Testing reports for critical suppliers (PDF format) • Quarterly Supplier Performance Dashboard reports (PDF format) • Annual Risk Management Effectiveness Review reports (PDF format) • Supplier selection criteria documentation (Word documents) • Supplier agreements with security and privacy requirements (PDF format) • Supplier monitoring logs showing continuous monitoring (System logs)",
  "Control test plan and procedures" : "• Select five third-party suppliers and verify Risk Assessments were updated in the past quarter • Review the last three monthly Security Compliance Verification reports • For two critical suppliers, verify Contingency Testing was conducted in the past year • Examine the most recent Quarterly Supplier Performance Dashboard to confirm monitoring • Select one supplier and verify all contractual requirements are being monitored • Control passes if third-party risk management controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Third-Party Risk Manager must implement corrective actions within 15 business days and conduct additional assessments"
},
{
  "Domain" : "Transparency & Communication",
  "Master" : "CO-1",
  "Topic" : "AI System Transparency",
  "Control Statement" : "The organisation shall ensure AI systems are designed and operated with appropriate transparency, enabling users and affected individuals to understand when they are interacting with AI, how the AI system impacts them, and what the system's capabilities and limitations are. This includes clear marking of AI-generated content, disclosure of automated decision-making, and provision of comprehensive documentation about system performance and intended use. The organisation must maintain accessibility standards in all transparency communications, provide explanations of AI-driven decisions when required by law, and ensure instructions and documentation are clear and accessible to intended audiences.",
  "ISO42001" : "7.4 A.6.2.7 A.8.2 A.9.3 A.9.4",
  "ISO27001" : "7.4 A.6.4",
  "ISO27701" : "A.7.3.2 A.7.3.3 A.7.3.10 B.8.2.3",
  "EU AI ACT" : "13.1-13.3 15.3 50.1-50.5 86.1-86.3",
  "NIST RMF" : "Map 1.2 Measure 4.1",
  "SOC2" : "CC2.2",
  "Key control activities" : "• Before system deployment, the Product Manager completes the Transparency Disclosure Form using the Transparency Framework • Monthly, the UX Researcher reviews user understanding of AI disclosures using the User Understanding Survey • For each system update, the Communications Manager updates disclosure documentation using the Disclosure Update Checklist • Quarterly, the Compliance Officer reviews transparency compliance using the Transparency Compliance Audit • Annually, the AI Governance Committee reviews transparency effectiveness using the Transparency Effectiveness Review",
  "Required Evidence" : "• Transparency Disclosure Forms for all AI systems (PDF format) • Monthly User Understanding Survey results (PDF format) • Disclosure Update Checklists for system updates (PDF format) • Quarterly Transparency Compliance Audit reports (PDF format) • Annual Transparency Effectiveness Review reports (PDF format) • AI system marking documentation with examples (PDF format) • Automated decision-making disclosure templates (Word documents) • System documentation with accessibility verification (PDF format)",
  "Control test plan and procedures" : "• Select three AI systems and verify Transparency Disclosure Forms were completed before deployment • Review the last three monthly User Understanding Survey results to confirm regular assessment • For two system updates from the past quarter, verify Disclosure Update Checklists were completed • Examine the most recent Quarterly Transparency Compliance Audit to confirm compliance verification • Test system interfaces to verify AI disclosure notices are present and clear • Control passes if transparency controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Product Manager must implement corrective actions within 10 business days and conduct additional verification"
},
{
  "Domain" : "Transparency & Communication",
  "Master" : "CO-2",
  "Topic" : "Stakeholder Engagement and Feedback",
  "Control Statement" : "The organisation shall implement comprehensive stakeholder engagement processes to collect, evaluate, and respond to feedback about AI system impacts and performance. This includes establishing mechanisms for regular stakeholder consultation, incorporating feedback into system improvements, and maintaining documentation of stakeholder engagement activities. The organisation must consider diverse perspectives, ensure feedback processes are accessible to all affected communities, and demonstrate how stakeholder input influences system development and operation. Regular reporting to stakeholders about system performance, impacts, and improvements must be maintained.",
  "ISO42001" : "A.3.3 A.8.3 A.8.5 A.10.4",
  "ISO27001" : "4.2 A.6.4",
  "ISO27701" : "A.7.3.4 A.7.3.5 A.7.3.9",
  "EU AI ACT" : "4.1 26.7 26.11",
  "NIST RMF" : "Govern 5.1 Govern 5.2 Map 5.2 Measure 3.3 Measure 4.3",
  "SOC2" : "CC2.2",
  "Key control activities" : "• Quarterly, the Stakeholder Engagement Manager conducts stakeholder consultations using the Consultation Framework • Monthly, the Feedback Manager analyzes stakeholder feedback using the Feedback Analysis Tool • For major system changes, the Communications Manager conducts stakeholder briefings using the Briefing Protocol • Semi-annually, the Inclusion Specialist reviews accessibility of engagement processes using the Accessibility Audit • Annually, the AI Governance Committee reviews engagement effectiveness using the Engagement Effectiveness Review",
  "Required Evidence" : "• Quarterly Stakeholder Consultation reports with findings (PDF format) • Monthly Stakeholder Feedback Analysis reports (PDF format) • Stakeholder Briefing documentation for major changes (PDF format) • Semi-annual Accessibility Audit reports for engagement processes (PDF format) • Annual Engagement Effectiveness Review reports (PDF format) • Stakeholder identification and mapping documentation (Excel format) • Feedback collection methodology documentation (Word documents) • Evidence of diverse stakeholder representation (PDF format)",
  "Control test plan and procedures" : "• Review the last two quarterly Stakeholder Consultation reports to confirm regular engagement • Examine the last three monthly Stakeholder Feedback Analysis reports to verify analysis • For two major system changes from the past six months, verify Stakeholder Briefings were conducted • Review the most recent Semi-annual Accessibility Audit to confirm inclusive engagement • Select one stakeholder feedback item and trace through to implementation of changes • Control passes if stakeholder engagement controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Stakeholder Engagement Manager must implement corrective actions within 15 business days and conduct additional engagement activities"
},
{
  "Domain" : "Incident Management",
  "Master" : "IM-1",
  "Topic" : "Incident Detection and Response",
  "Control Statement" : "The organisation shall establish and maintain a comprehensive incident management process for AI systems. This process must include mechanisms for detecting incidents, assessing their severity, implementing immediate response measures, and conducting thorough investigations. The organisation shall maintain documented procedures for incident response, ensure adequate resources are available for incident handling, and verify that response teams have appropriate expertise. Response procedures must address both technical and privacy-related incidents, with specific provisions for high-risk AI systems.",
  "ISO42001" : "A.8.4",
  "ISO27001" : "A.16.1 A.12.7",
  "ISO27701" : "16.2.1 A.7.3.7 B.8.5.4",
  "EU AI ACT" : 73.6,
  "NIST RMF" : "Manage 4.3",
  "SOC2" : "CC7.4 P6.1 P6.2",
  "Key control activities" : "• Daily, the Incident Response team reviews incident alerts using the Incident Detection System • For each incident, the Incident Manager completes the Incident Response Form using the Incident Management Process • Monthly, the Incident Analysis team reviews incident trends using the Incident Analysis Dashboard • Quarterly, the Incident Response team conducts incident response exercises using the Response Testing Protocol • Annually, the AI Governance Committee reviews incident response effectiveness using the Effectiveness Review Framework",
  "Required Evidence" : "• Daily Incident Alert Review logs (System logs) • Incident Response Forms for all incidents (PDF format) • Monthly Incident Trend Analysis reports (PDF format) • Quarterly Incident Response Exercise reports (PDF format) • Annual Incident Response Effectiveness Review reports (PDF format) • Incident response procedure documentation (Word documents) • Incident severity classification documentation (PDF format) • Incident response team training records (LMS reports)",
  "Control test plan and procedures" : "• Review incident alert logs from the past 7 days to verify daily review occurred • Select five incidents from the past quarter and verify Incident Response Forms were properly completed • Review the last three monthly Incident Trend Analysis reports to confirm regular analysis • Examine the most recent Quarterly Incident Response Exercise report to verify testing • Test the incident detection system by creating a test incident and verifying proper detection • Control passes if incident detection and response controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Incident Response Manager must implement corrective actions within 10 business days and conduct additional training"
},
{
  "Domain" : "Incident Management",
  "Master" : "IM-2",
  "Topic" : "Incident Reporting and Notification",
  "Control Statement" : "The organisation shall implement processes for timely reporting of serious incidents to relevant suppliers, customers, authorities, affected individuals, and other stakeholders as required by applicable regulations or internal policy. This includes maintaining clear notification timelines based on incident severity, ensuring completeness and accuracy of incident reports. The organisation must document all notifications and maintain evidence of compliance.",
  "ISO42001" : "A.8.4",
  "ISO27001" : "A.16.1 A.16.2",
  "ISO27701" : "16.2.2 B.8.5.4 B.8.5.5",
  "EU AI ACT" : "73.1-73.5 73.9 73.10",
  "NIST RMF" : "Manage 4.3",
  "SOC2" : "P6.3 P6.4",
  "Key control activities" : "• For each reportable incident, the Incident Manager completes the Incident Notification Form using the Notification Process • Monthly, the Compliance Officer reviews notification compliance using the Notification Compliance Checklist • After each incident notification, the Communications Manager verifies stakeholder notifications using the Notification Verification List • Quarterly, the Incident Response team reviews notification effectiveness using the Notification Effectiveness Report • Annually, the AI Governance Committee reviews reporting procedures using the Reporting Procedure Review",
  "Required Evidence" : "• Incident Notification Forms for all reportable incidents (PDF format) • Monthly Notification Compliance Checklist reports (PDF format) • Stakeholder Notification Verification Lists for all notifications (PDF format) • Quarterly Notification Effectiveness reports (PDF format) • Annual Reporting Procedure Review reports (PDF format) • Notification timeline documentation with timestamps (Excel format) • Authority notification templates with approval history (Word documents) • Evidence of timely notifications to relevant authorities (Email archives)",
  "Control test plan and procedures" : "• Select three reportable incidents from the past quarter and verify Incident Notification Forms were completed • For selected incidents, verify notifications were made within required timeframes • Review documentation to confirm all required stakeholders were notified • Examine the most recent Quarterly Notification Effectiveness report to verify process evaluation • Test the notification process by conducting a simulation and verifying proper notification • Control passes if incident reporting controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Incident Manager must implement corrective actions within 5 business days and conduct additional training"
},
{
  "Domain" : "Incident Management",
  "Master" : "IM-3",
  "Topic" : "Incident Analysis and Improvement",
  "Control Statement" : "The organisation shall analyse incidents to identify root causes, assess the effectiveness of response measures, and implement improvements to prevent recurrence. This includes conducting post-incident reviews, documenting lessons learned, updating incident response procedures based on experience, and verifying the effectiveness of corrective actions. The organisation must maintain records of all incident analyses and resulting improvements.",
  "ISO42001" : "A.8.4",
  "ISO27001" : "A.16.3",
  "ISO27701" : "16.2.1",
  "EU AI ACT" : 73.6,
  "NIST RMF" : "Manage 4.3",
  "SOC2" : "P6.5",
  "Key control activities" : "• After each incident, the Incident Analysis team conducts root cause analysis using the Root Cause Analysis Framework • Monthly, the Incident Review Committee reviews incident analyses using the Incident Review Process • Quarterly, the AI Safety team analyzes safety incidents using the Safety Incident Analysis Protocol • After major incidents, the Post-Incident Review team conducts comprehensive reviews using the Major Incident Review Process • Annually, the AI Governance Committee reviews incident analysis effectiveness using the Analysis Effectiveness Review",
  "Required Evidence" : "• Root Cause Analysis reports for all incidents (PDF format) • Monthly Incident Review Committee meeting minutes (PDF format) • Quarterly Safety Incident Analysis reports (PDF format) • Major Incident Review reports for all major incidents (PDF format) • Annual Analysis Effectiveness Review reports (PDF format) • Incident analysis methodology documentation (Word documents) • Corrective action tracking logs with implementation status (Excel format) • Incident analysis team training records (LMS reports)",
  "Control test plan and procedures" : "• Select five incidents from the past quarter and verify Root Cause Analysis reports were completed • Review the last three monthly Incident Review Committee meeting minutes to confirm regular reviews • For one major incident from the past six months, verify a comprehensive review was conducted • Examine corrective action tracking to confirm implementation and effectiveness monitoring • Review the most recent Annual Analysis Effectiveness Review to verify process evaluation • Control passes if incident analysis controls are consistently implemented with proper documentation; fails if controls are inconsistently implemented or inadequately documented • If failure, the Incident Analysis Manager must implement corrective actions within 15 business days and conduct additional training"
}]}